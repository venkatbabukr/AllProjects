{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function BuildTree(Dataset D, FeatureSet F):\n",
    "    Create a node N\n",
    "\n",
    "    If all examples in D are of the same class:\n",
    "        Mark N as a leaf node with that class\n",
    "        Return N\n",
    "\n",
    "    If F is empty or other stopping criteria are met (e.g., max depth, min samples):\n",
    "        Mark N as a leaf node with the most common class in D\n",
    "        Return N\n",
    "\n",
    "    Select the best feature and threshold for split:\n",
    "        best_feature, best_threshold = None, None\n",
    "        min_gini = inf\n",
    "\n",
    "        For each feature f in F:\n",
    "            For each value v in feature f (or for a set of candidate thresholds):\n",
    "                Partition D into D_left and D_right based on the threshold v\n",
    "                gini_impurity = CalculateGiniImpurity(D_left, D_right)\n",
    "\n",
    "                If gini_impurity < min_gini:\n",
    "                    min_gini = gini_impurity\n",
    "                    best_feature = f\n",
    "                    best_threshold = v\n",
    "\n",
    "    Use best_feature and best_threshold to split D into D_left and D_right\n",
    "\n",
    "    Node N's splitting criterion is (best_feature <= best_threshold)\n",
    "    N.left_child = BuildTree(D_left, F)\n",
    "    N.right_child = BuildTree(D_right, F)\n",
    "\n",
    "    Return N\n",
    "\n",
    "Function CalculateGiniImpurity(D_left, D_right):\n",
    "    size_left = size of D_left\n",
    "    size_right = size of D_right\n",
    "    size_total = size_left + size_right\n",
    "\n",
    "    gini_left = 1 - sum((count of each class in D_left / size_left)^2)\n",
    "    gini_right = 1 - sum((count of each class in D_right / size_right)^2)\n",
    "\n",
    "    weighted_gini = (size_left / size_total) * gini_left + (size_right / size_total) * gini_right\n",
    "\n",
    "    Return weighted_gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_iris()\n",
    "X, y, column_names = data['data'], data['target'], data['feature_names']\n",
    "X = pd.DataFrame(X, columns = column_names)\n",
    "X['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.drop(columns = 'target'), X['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, random_state = 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # links to the left and right child nodes\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        # derived from splitting criteria\n",
    "        self.column = None\n",
    "        self.threshold = None\n",
    "        \n",
    "        # probability for object inside the Node to belong for each of the given classes\n",
    "        self.probas = None\n",
    "        # depth of the given node\n",
    "        self.depth = None\n",
    "        \n",
    "        # if it is the root Node or not\n",
    "        self.is_terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth = 3, min_samples_leaf = 1, min_samples_split = 2):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "        self.classes = None\n",
    "        \n",
    "        # Decision tree itself\n",
    "        self.Tree = None\n",
    "    \n",
    "    def nodeProbas(self, y):\n",
    "        '''\n",
    "        Calculates probability of class in a given node\n",
    "        '''\n",
    "        \n",
    "        probas = []\n",
    "        \n",
    "        # for each unique label calculate the probability for it\n",
    "        for one_class in self.classes:\n",
    "            proba = y[y == one_class].shape[0] / y.shape[0]\n",
    "            probas.append(proba)\n",
    "        return np.asarray(probas)\n",
    "\n",
    "    def gini(self, probas):\n",
    "        '''\n",
    "        Calculates gini criterion\n",
    "        '''\n",
    "        \n",
    "        return 1 - np.sum(probas**2)\n",
    "    \n",
    "    def calcImpurity(self, y):\n",
    "        '''\n",
    "        Wrapper for the impurity calculation. Calculates probas first and then passses them\n",
    "        to the Gini criterion\n",
    "        '''\n",
    "        \n",
    "        return self.gini(self.nodeProbas(y))\n",
    "    \n",
    "    def calcBestSplit(self, X, y):\n",
    "        '''\n",
    "        Calculates the best possible split for the concrete node of the tree\n",
    "        '''\n",
    "        \n",
    "        bestSplitCol = None\n",
    "        bestThresh = None\n",
    "        bestInfoGain = -999\n",
    "        \n",
    "        impurityBefore = self.calcImpurity(y)\n",
    "        \n",
    "        # for each column in X\n",
    "        for col in range(X.shape[1]):\n",
    "            x_col = X[:, col]\n",
    "            \n",
    "            # for each value in the column\n",
    "            for x_i in x_col:\n",
    "                threshold = x_i\n",
    "                y_right = y[x_col > threshold]\n",
    "                y_left = y[x_col <= threshold]\n",
    "                \n",
    "                if y_right.shape[0] == 0 or y_left.shape[0] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # calculate impurity for the right and left nodes\n",
    "                impurityRight = self.calcImpurity(y_right)\n",
    "                impurityLeft = self.calcImpurity(y_left)\n",
    "                \n",
    "                # calculate information gain\n",
    "                infoGain = impurityBefore\n",
    "                infoGain -= (impurityLeft * y_left.shape[0] / y.shape[0]) + (impurityRight * y_right.shape[0] / y.shape[0])\n",
    "                \n",
    "                # is this infoGain better then all other?\n",
    "                if infoGain > bestInfoGain:\n",
    "                    bestSplitCol = col\n",
    "                    bestThresh = threshold\n",
    "                    bestInfoGain = infoGain\n",
    "                    \n",
    "        \n",
    "        # if we still didn't find the split\n",
    "        if bestInfoGain == -999:\n",
    "            return None, None, None, None, None, None\n",
    "        \n",
    "        # making the best split\n",
    "        \n",
    "        x_col = X[:, bestSplitCol]\n",
    "        x_left, x_right = X[x_col <= bestThresh, :], X[x_col > bestThresh, :]\n",
    "        y_left, y_right = y[x_col <= bestThresh], y[x_col > bestThresh]\n",
    "        \n",
    "        return bestSplitCol, bestThresh, x_left, y_left, x_right, y_right\n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "    def buildDT(self, X, y, node):\n",
    "        '''\n",
    "        Recursively builds decision tree from the top to bottom\n",
    "        '''\n",
    "        \n",
    "        # checking for the terminal conditions\n",
    "        \n",
    "        if node.depth >= self.max_depth:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        if X.shape[0] < self.min_samples_split:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        # calculating current split\n",
    "        splitCol, thresh, x_left, y_left, x_right, y_right = self.calcBestSplit(X, y)\n",
    "        \n",
    "        if splitCol is None:\n",
    "            node.is_terminal = True\n",
    "            \n",
    "        if x_left.shape[0] < self.min_samples_leaf or x_right.shape[0] < self.min_samples_leaf:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        node.column = splitCol\n",
    "        node.threshold = thresh\n",
    "        \n",
    "        # creating left and right child nodes\n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.probas = self.nodeProbas(y_left)\n",
    "        \n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.probas = self.nodeProbas(y_right)\n",
    "        \n",
    "        # splitting recursevely\n",
    "        self.buildDT(x_right, y_right, node.right)\n",
    "        self.buildDT(x_left, y_left, node.left)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Standard fit function to run all the model training\n",
    "        '''\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X = np.asarray(X)\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        # root node creation\n",
    "        self.Tree = Node()\n",
    "        self.Tree.depth = 1\n",
    "        self.Tree.probas = self.nodeProbas(y)\n",
    "        \n",
    "        self.buildDT(X, y, self.Tree)\n",
    "    \n",
    "    def predictSample(self, x, node):\n",
    "        '''\n",
    "        Passes one object through decision tree and return the probability of it to belong to each class\n",
    "        '''\n",
    "       \n",
    "    \n",
    "        # if we have reached the terminal node of the tree\n",
    "        if node.is_terminal:\n",
    "            return node.probas\n",
    "        \n",
    "        if x[node.column] > node.threshold:\n",
    "            probas = self.predictSample(x, node.right)\n",
    "        else:\n",
    "            probas = self.predictSample(x, node.left)\n",
    "            \n",
    "        return probas\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Returns the labels for each X\n",
    "        '''\n",
    "        \n",
    "        if type(X) == pd.DataFrame:\n",
    "            X = np.asarray(X)\n",
    "            \n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred = np.argmax(self.predictSample(x, self.Tree))\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 719 ms\n",
      "Wall time: 720 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeClassifier(max_depth = 10, min_samples_leaf=2, min_samples_split=2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for self built model 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_val)\n",
    "print(f'Accuracy for self built model {accuracy_score(y_val, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sklearn Decision Tree 0.8947368421052632\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth = 10)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print(f'Accuracy for sklearn Decision Tree {accuracy_score(y_val, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
