{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Content"
      ],
      "metadata": {
        "id": "hATLL9KgicfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **XGBoost**\n",
        "    \n",
        "\n",
        "- **LightGBM**\n",
        "\n",
        "- **Stacking**\n",
        "\n",
        "\n",
        "- **Cascading**\n",
        "\n"
      ],
      "metadata": {
        "id": "MvfOTgoCjDut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "ChLPtBdLjIG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/297/original/z.png?1705487607' width=700></center>"
      ],
      "metadata": {
        "id": "5jJl6-Bxj_ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sklearn's GBDT implentation is not the best implementation.\n",
        "\n",
        "Recall how much time it took (>30 mins)\n",
        "- to do hyperparam tuning/ training single model using sklearn GBDT"
      ],
      "metadata": {
        "id": "vc2CwqHYyoJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where **XGBoost** steps in\n",
        "\n",
        "\n",
        "XGBoost provides **optimized** **implementation** of GBDT\n",
        "- which helps in reducing model training process.\n"
      ],
      "metadata": {
        "id": "dZFVcTDsyy-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it does that"
      ],
      "metadata": {
        "id": "zdJJhyb0z_KG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What optimization does XGBoost provides ?"
      ],
      "metadata": {
        "id": "utFdnygR0BUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parallelization of features selection"
      ],
      "metadata": {
        "id": "QuzJ7W_k0D0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While building Decision Trees,\n",
        "- there will be n features to consider while splitting the node.\n",
        "\n",
        "<br>\n",
        "\n",
        "The computation of Information Gain(s) of the features is done in parallel\n",
        "- which helps in reducing the training time"
      ],
      "metadata": {
        "id": "DHyUSCv-3AZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/298/original/z.png?1705487635' width=700></center>"
      ],
      "metadata": {
        "id": "UitIh8WD4cRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parallelization in building DT"
      ],
      "metadata": {
        "id": "JfSLGeZq6Azg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While building a DT,\n",
        "- both subtrees (left and right) can be build in parallel\n",
        "- as there is no dependency between them.\n",
        "\n",
        "which helps in making the process faster and efficient."
      ],
      "metadata": {
        "id": "F_BLBRO077iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/299/original/z.png?1705487664' width=700></center>"
      ],
      "metadata": {
        "id": "BhU7kRjC8Qls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizing thresholding in numerical feature"
      ],
      "metadata": {
        "id": "IG5gHAux9mVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conventional DTs,\n",
        "- While finding the threshold for numerical feature\n",
        "    - all the numerical values are tested to find one with maximum information gain.\n",
        "\n",
        "Which makes this whole process slow.\n",
        "\n"
      ],
      "metadata": {
        "id": "2B2-c7zsANbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost optimizes this by using **histogram based binning**\n",
        "\n",
        "**What's histogram based binning ?**\n",
        "\n",
        "- In simple terms, it creates discrete bins (percentile  binning) using these continuos values\n",
        "- And then selects threshold using the bins instead of trying every single value.\n",
        "\n",
        "i.e. it uses approximation.\n",
        "\n",
        "- which helps in making the process faster."
      ],
      "metadata": {
        "id": "4fg-oB5kAd7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/300/original/z.png?1705487688' width=700></center>"
      ],
      "metadata": {
        "id": "VH_R3mSABY3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to dive deep into it,\n",
        "\n",
        "here's the link to the research paper: https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf\n",
        "- published in 2016"
      ],
      "metadata": {
        "id": "wJjGRw45DDT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into the numerous hyperparams provided by XGBoost"
      ],
      "metadata": {
        "id": "Qr134KDcDHxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "NQLvLuYeDmN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost doc: https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier"
      ],
      "metadata": {
        "id": "XJ1KOxitDodO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/301/original/z.png?1705487728' width=700></center>\n"
      ],
      "metadata": {
        "id": "ggo5yLxyE_w_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/302/original/z.png?1705487755' width=700></center>\n",
        "\n",
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/303/original/z.png?1705487781' width=700></center>"
      ],
      "metadata": {
        "id": "rWA8kFe8GAGO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHwaJ4RCU2HS"
      },
      "source": [
        "1. **Eta**: or the learning rate is the shrinking/regularization term\n",
        "\n",
        "2. **min_split_loss** specify the minimum Information Gain which you want for further split.\n",
        "\n",
        "    - If the min_split_loss value of the model is increased,\n",
        "    - the splitting stops if the min_split_loss is not met.\n",
        "    \n",
        "Due to this the depth decreases resulting in shallow tress.\n",
        "\n",
        "- Hence,results in the underfitting of the model.\n",
        "\n",
        "\n",
        "3. **max_depth**, this parameter is used to set the depth of the base learners  \n",
        "\n",
        "4. **min_child_weight**: you can increase the weight of the child due to which the splitting stops if the required threshold is not met\n",
        "\n",
        "5. **subsample**. is nothing but the row sampling rate.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It provides various levels of column sampling\n",
        "\n",
        "i.e.\n",
        "- column sampling ratio for each tree\n",
        "- column sampling ratio for each level\n",
        "- column sampling ratio for each split"
      ],
      "metadata": {
        "id": "E8MknoYcFujR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It even provides L1 and L2 regularization for weights ($γ_m$)"
      ],
      "metadata": {
        "id": "AFzb0JGdGNyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are aware of the hyperparams,\n",
        "\n",
        "let's give them a try"
      ],
      "metadata": {
        "id": "MLYVy6dCMfQt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvsDq-PSfS29"
      },
      "source": [
        "### Code walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "!gdown 171Yoe_GSapyrmOnD9oBzHWNOD_OnQs0F\n",
        "!gdown 1hnIlTPW3AMeB69EbeaXCRIrpMVT1Vwmc\n",
        "!gdown 1nZtB_RtxMg_MgoRczb8UWQX-AEK_l3qE\n",
        "!gdown 1zLDUErwKdmF-RacOyHEuI_z_46LssQtP\n",
        "\n",
        "\n",
        "with open('X_train.pickle', 'rb') as handle:\n",
        "    X_train = pickle.load(handle)\n",
        "\n",
        "with open('X_test.pickle', 'rb') as handle:\n",
        "    X_test = pickle.load(handle)\n",
        "\n",
        "with open('Y_train.pickle', 'rb') as handle:\n",
        "    y_train = pickle.load(handle)\n",
        "\n",
        "with open('Y_test.pickle', 'rb') as handle:\n",
        "    y_test = pickle.load(handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfw5uJWwYTrZ",
        "outputId": "1eb77af5-69fc-46f6-8784-40e40b66db15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=171Yoe_GSapyrmOnD9oBzHWNOD_OnQs0F\n",
            "To: /content/Y_test.pickle\n",
            "100% 31.7k/31.7k [00:00<00:00, 83.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hnIlTPW3AMeB69EbeaXCRIrpMVT1Vwmc\n",
            "To: /content/X_test.pickle\n",
            "100% 253k/253k [00:00<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nZtB_RtxMg_MgoRczb8UWQX-AEK_l3qE\n",
            "To: /content/Y_train.pickle\n",
            "100% 126k/126k [00:00<00:00, 130MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zLDUErwKdmF-RacOyHEuI_z_46LssQtP\n",
            "To: /content/X_train.pickle\n",
            "100% 1.01M/1.01M [00:00<00:00, 152MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiwuBmp0fUqI"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "params = {\n",
        "        \"n_estimators\": [50,100,150,200],\n",
        "        \"max_depth\" : [3, 4, 5, 7],\n",
        "        \"learning_rate\": [0.1, 0.2, 0.3],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        }\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=20, silent=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isosAJtbfZr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9142a19-597a-4b75-d6c3-d7b954ada1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[03:38:03] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_leaf_nodes\", \"silent\" } are not used.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "random_search = RandomizedSearchCV(xgb,\n",
        "                                   param_distributions=params,\n",
        "                                   n_iter=10,\n",
        "                                   scoring='accuracy',\n",
        "                                   n_jobs=-1,\n",
        "                                   cv=3,\n",
        "                                   verbose=2)\n",
        "\n",
        "\n",
        "start = dt.datetime.now()\n",
        "random_search.fit(X_train, y_train)\n",
        "end = dt.datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = random_search.cv_results_\n",
        "\n",
        "for i in range(len(res[\"params\"])):\n",
        "  print(f\"Parameters:{res['params'][i]} Mean_score: {res['mean_test_score'][i]} Rank: {res['rank_test_score'][i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woTuckVVNj8H",
        "outputId": "7e382fa3-76bd-46ed-9579-6186d0dc3ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:{'subsample': 0.6, 'n_estimators': 200, 'max_leaf_nodes': 80, 'max_depth': 5, 'learning_rate': 0.3, 'colsample_bytree': 0.6} Mean_score: 0.958523592085236 Rank: 4\n",
            "Parameters:{'subsample': 0.8, 'n_estimators': 150, 'max_leaf_nodes': 40, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Mean_score: 0.9615677321156774 Rank: 2\n",
            "Parameters:{'subsample': 1.0, 'n_estimators': 200, 'max_leaf_nodes': 80, 'max_depth': 7, 'learning_rate': 0.2, 'colsample_bytree': 0.8} Mean_score: 0.9650558092338914 Rank: 1\n",
            "Parameters:{'subsample': 0.8, 'n_estimators': 150, 'max_leaf_nodes': 40, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8} Mean_score: 0.9540208016235413 Rank: 6\n",
            "Parameters:{'subsample': 0.8, 'n_estimators': 100, 'max_leaf_nodes': 40, 'max_depth': 5, 'learning_rate': 0.2, 'colsample_bytree': 0.6} Mean_score: 0.9534500253678336 Rank: 7\n",
            "Parameters:{'subsample': 0.6, 'n_estimators': 150, 'max_leaf_nodes': 20, 'max_depth': 5, 'learning_rate': 0.2, 'colsample_bytree': 0.8} Mean_score: 0.9607432775240993 Rank: 3\n",
            "Parameters:{'subsample': 1.0, 'n_estimators': 50, 'max_leaf_nodes': 40, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 1.0} Mean_score: 0.9384830035514966 Rank: 9\n",
            "Parameters:{'subsample': 0.6, 'n_estimators': 100, 'max_leaf_nodes': 40, 'max_depth': 7, 'learning_rate': 0.2, 'colsample_bytree': 0.6} Mean_score: 0.9571283612379503 Rank: 5\n",
            "Parameters:{'subsample': 1.0, 'n_estimators': 200, 'max_leaf_nodes': 80, 'max_depth': 4, 'learning_rate': 0.1, 'colsample_bytree': 0.6} Mean_score: 0.9431760527650939 Rank: 8\n",
            "Parameters:{'subsample': 0.8, 'n_estimators': 50, 'max_leaf_nodes': 40, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.6} Mean_score: 0.9205986808726534 Rank: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Time taken for fits : {end - start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8El57tWNvWE",
        "outputId": "c28197fa-587f-4492-935d-6d01ebf3933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for fits : 0:09:44.158693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65dd49bc-4e2e-47fb-e038-6ab604ab4af8",
        "id": "foqmUdkEN1do"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=7, max_leaf_nodes=80,\n",
            "              max_leaves=None, min_child_weight=None, missing=nan,\n",
            "              monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
            "              num_class=20, num_parallel_tree=None, ...)\n"
          ]
        }
      ],
      "source": [
        "print(random_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e87b1c-b8ba-4fd5-852c-9f808cc75a2d",
        "id": "-RJeRbT_N1d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03:45:08] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_leaf_nodes\", \"silent\" } are not used.\n",
            "\n",
            "Model acc 0.9807253360385493\n"
          ]
        }
      ],
      "source": [
        "xgb = random_search.best_estimator_\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model acc\",xgb.score(X_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that\n",
        "- It took us 10 mins to hyperparam tune XGB vs > 30 mins in sklearn GBDT\n"
      ],
      "metadata": {
        "id": "9Jqy5Gn6VlEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "A0GAL4vvZE_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research paper link: https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf\n",
        "\n",
        "- published in 2017\n",
        "- by Microsoft Research"
      ],
      "metadata": {
        "id": "YY6nBgAI4JAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM is another implementation of GBDT\n",
        "- uses insane optimization to make the training efficient.\n",
        "\n",
        "Surprisingly, it is **faster than XGBoost**"
      ],
      "metadata": {
        "id": "v5iEP8niE4KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What makes LightGBM faster?"
      ],
      "metadata": {
        "id": "3d8AScTcGP9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "\n",
        "How can we make an algo train faster?\n",
        "\n",
        "a. reduce number of datapoints\n",
        "b. reduce number of features\n",
        "c. Both\n",
        "d. None of the aboe\n",
        "\n",
        "Ans: c. Both\n",
        "\n",
        "Reducing the number of datapoint or features will help algo train faster.\n",
        "```"
      ],
      "metadata": {
        "id": "6Bh4ExmqrTQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what LightGBM does with its optimization\n",
        "\n",
        " Let's look into that"
      ],
      "metadata": {
        "id": "BbuKE6MkGkO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GOSS (Gradient-based One-Side Sampling)"
      ],
      "metadata": {
        "id": "ITa83Y99Gpz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say, we are training the $m^{th}$ model of GBDT"
      ],
      "metadata": {
        "id": "050ZAWqXGw6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/304/original/z.png?1705487819' width=800></center>"
      ],
      "metadata": {
        "id": "6-YPF13IKePs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training,\n",
        "- there will be lot of datapoints with small residual (pseudo residual)\n",
        "\n",
        "So, what LightGBM does is\n",
        "- it drops all the points from training where the error is very small.\n",
        "\n",
        "Intuitively,\n",
        "- It is doing **smart sampling** by\n",
        "    - reducing the size of training data\n",
        "    - which make the training process faster."
      ],
      "metadata": {
        "id": "bv9f9-_mPIY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### But, why does one side sampling means ?"
      ],
      "metadata": {
        "id": "FjSZgRYePc_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/305/original/z.png?1705487847' width=800></center>"
      ],
      "metadata": {
        "id": "XR_DO-Ufga92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are sampling the points from one side of the distribution\n",
        "- Hence, the name Gradient based One Side sampling\n",
        "\n"
      ],
      "metadata": {
        "id": "b_C-wP1NgbSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on to next optimization"
      ],
      "metadata": {
        "id": "KAxXN7-dgv6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EFB (Exclusive Feature Bundling)"
      ],
      "metadata": {
        "id": "9ZemxkdEg4I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the name suggests,\n",
        "- it scans through all the features\n",
        "- and tries to find feature pairs which are exclusive"
      ],
      "metadata": {
        "id": "BzH35hMxg-e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What does exclusive feature mean ?"
      ],
      "metadata": {
        "id": "ir79F8OlhVRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say, we have an OHE encoded categorical feature\n",
        "\n",
        "For example:\n",
        "- Gender when encoded using OHE gave us two features Male & Female."
      ],
      "metadata": {
        "id": "fI-Ygl_cidCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/306/original/z.png?1705487872' width=800></center>"
      ],
      "metadata": {
        "id": "_AenW4pJkTHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that\n",
        "- when value of Male is 1\n",
        "- Female is 0\n",
        "\n",
        "i.e. when $f_3$ (Male) is one, other featue ($f_5$) is zero\n",
        "- The behaviour is called exclusivity."
      ],
      "metadata": {
        "id": "3rZfjyGooNuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### But, it is obvious that when Male feature value is 1, female feature value will be zero.\n",
        "\n",
        "Yes.\n",
        "But\n",
        "- a problem has numerous features\n",
        "- and we can't check manually which features are exclusive\n",
        "\n",
        "There can be a case where two categorical features\n",
        "- say, for example:\n",
        "    - binary feature: whether person likes football ?\n",
        "    - and another feature: whether person likes swimming ?\n",
        "\n",
        "There can be chance that this pair of feature is exclusive for the given dataset."
      ],
      "metadata": {
        "id": "sF5EiKTnon4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What happens after it has identified Exclusive feature pair ?"
      ],
      "metadata": {
        "id": "03IberJMowIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/307/original/z.png?1705487903' width=800></center>"
      ],
      "metadata": {
        "id": "EO_MVND_klIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It'll **group** the **features** into single feature\n",
        "- and **create** **a new feature**\n",
        "\n",
        "such that\n",
        "- new feature will have information of both the feature\n",
        "\n",
        "\n",
        "Intuitively,\n",
        "- it is performing **dimensionality reduction**\n",
        "    - which helps in **training** GBDT **faster**."
      ],
      "metadata": {
        "id": "qajSyrncqewH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to deep dive into it,\n",
        "\n",
        "here a blog explaining it in detail: https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e"
      ],
      "metadata": {
        "id": "NlNACJw_q0qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into how can we implement it"
      ],
      "metadata": {
        "id": "kLvJ1Hf2sGhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code walkthough"
      ],
      "metadata": {
        "id": "m9ZTiPXksPcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
      ],
      "metadata": {
        "id": "X7Fvs7gPsRDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "#Refer: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "import datetime as dt\n",
        "gridParams = {\n",
        "    'learning_rate': [0.1, 0.3, 0.5],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['multiclass'],\n",
        "    'max_depth' : [5,6,7,8],\n",
        "    'colsample_bytree' : [0.5,0.7],\n",
        "    'subsample' : [0.5,0.7],\n",
        "    'metric':['multi_error'],\n",
        "    }\n",
        "\n",
        "clf = lgb.LGBMClassifier(num_classes=20)\n",
        "random_cv = RandomizedSearchCV(clf,gridParams,verbose=3,cv=3,n_jobs = -1,n_iter=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "16J2SAcbsXs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = dt.datetime.now()\n",
        "random_cv.fit(X_train,y_train)\n",
        "end = dt.datetime.now()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU7WuYJFsr8P",
        "outputId": "42a0f41b-0f89-465d-94ac-339055febf45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = random_cv.cv_results_\n",
        "\n",
        "for i in range(len(res[\"params\"])):\n",
        "  print(f\"Parameters:{res['params'][i]} Mean_score: {res['mean_test_score'][i]} Rank: {res['rank_test_score'][i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d647e534-6aa3-4ad0-d946-9635d5ebf497",
        "id": "_hONrMWmtMl_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 8, 'learning_rate': 0.5, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'} Mean_score: 0.16324200913242007 Rank: 7\n",
            "Parameters:{'subsample': 0.5, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 7, 'learning_rate': 0.3, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'} Mean_score: 0.9692415017757483 Rank: 1\n",
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 8, 'learning_rate': 0.3, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'} Mean_score: 0.9681633688483003 Rank: 2\n",
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'boosting_type': 'gbdt'} Mean_score: 0.1513191273465246 Rank: 9\n",
            "Parameters:{'subsample': 0.5, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 8, 'learning_rate': 0.5, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'} Mean_score: 0.16324200913242007 Rank: 7\n",
            "Parameters:{'subsample': 0.5, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 6, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'boosting_type': 'gbdt'} Mean_score: 0.1924150177574835 Rank: 5\n",
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 8, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'boosting_type': 'gbdt'} Mean_score: 0.16736428209030949 Rank: 6\n",
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 7, 'learning_rate': 0.3, 'colsample_bytree': 0.5, 'boosting_type': 'gbdt'} Mean_score: 0.9635337392186707 Rank: 3\n",
            "Parameters:{'subsample': 0.5, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.7, 'boosting_type': 'gbdt'} Mean_score: 0.13051750380517502 Rank: 10\n",
            "Parameters:{'subsample': 0.7, 'objective': 'multiclass', 'metric': 'multi_error', 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'boosting_type': 'gbdt'} Mean_score: 0.9564307458143074 Rank: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Time taken for fits : {end - start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504c3c11-c7bc-4f13-ef4f-e4ff75fe61f6",
        "id": "qNBv_GF-tMmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for fits : 0:00:57.177334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9dff8b-796e-4714-9e21-204199bf0746",
        "id": "n5-WZRj4tMmA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBMClassifier(colsample_bytree=0.7, learning_rate=0.3, max_depth=7,\n",
            "               metric='multi_error', num_classes=20, objective='multiclass',\n",
            "               subsample=0.5)\n"
          ]
        }
      ],
      "source": [
        "print(random_cv.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a6b659-046d-4052-f576-363c2f24b512",
        "id": "jYg1TprPtMmA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model acc 0.9835150900329698\n"
          ]
        }
      ],
      "source": [
        "lgb = random_cv.best_estimator_\n",
        "\n",
        "lgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model acc\",lgb.score(X_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that\n",
        "- It only took 57 sec to train\n",
        "- and its performance is comparable to XGBoost implementation"
      ],
      "metadata": {
        "id": "VTiHGKqGs5Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, that we are finished with GBDT.\n",
        "\n",
        "Let's learn about some other ensemble techniques"
      ],
      "metadata": {
        "id": "thOun0fNtyhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking"
      ],
      "metadata": {
        "id": "9MzY2JLJvrDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does stacking works ?\n"
      ],
      "metadata": {
        "id": "BIp1R-wPvr62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we are entering a kaggle competition\n",
        "- and we have a team of m members\n",
        "\n",
        "The team decided that each individual memeber will train its own model.\n",
        "\n",
        "So, on a give training dataset\n",
        "- there will be m well hyperparameter tuned model\n",
        "\n",
        "\n",
        "Note that\n",
        "- all m models can be different\n",
        "- i.e. M1 can be logistic regression, M2 can be Knn etc"
      ],
      "metadata": {
        "id": "Jq3y1U1gvy51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/308/original/z.png?1705487939' width=700></center>"
      ],
      "metadata": {
        "id": "Ml8HFyFowe1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got the individual well trained model\n",
        "\n",
        "#### But, how do we combine them?"
      ],
      "metadata": {
        "id": "26G3QxcOxrtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each model will give us a prediction\n",
        "\n",
        "\n",
        "Using these predictions,\n",
        "- we train another model\n",
        "    - i.e. using predictions ($p_1, p_2, p_3 .. p_m$) as input data\n",
        "    - and original target variable $y$ as target variable\n",
        "    - we train a model\n",
        "- This model is called meta classifier\n",
        "\n",
        "Note:\n",
        "- Instead of predictions,\n",
        "    - we can take probabilties as input features for meta classifier"
      ],
      "metadata": {
        "id": "djzWOBsxxyEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/309/original/z.png?1705487973' width=700></center>"
      ],
      "metadata": {
        "id": "WaJToP5oyRs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that\n",
        "- Meta classifer can be any model as well (Log. reg, GBDT etc)\n",
        "\n",
        "The prediction given by Meta classifier\n",
        "- is treated as final prediction ($ŷ$)\n",
        "\n",
        "\n",
        "And this whole concept is called as **stacking** of models"
      ],
      "metadata": {
        "id": "JG53jT770MO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The idea looks interesting. But, why don't we use it ?"
      ],
      "metadata": {
        "id": "on8DZ1Go0bVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/310/original/z.png?1705488004' width=700></center>"
      ],
      "metadata": {
        "id": "IrVj8NuikuQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't use it due to its extensive **time complexity**\n",
        "\n",
        "It takes a lot of time to fine tune M base models\n",
        "- and then training the predictions on Meta classifier\n",
        "\n",
        "Whole process becomes time consuming\n",
        "\n"
      ],
      "metadata": {
        "id": "BZDvFonO3W5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However,\n",
        "- it is extensively used in kaggle competition\n",
        "- where the goal is to get the top score\n",
        "- and not the fast models"
      ],
      "metadata": {
        "id": "P5M_AMvc4E4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a link to the MLXTEND implementation of Stacking classifir: https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"
      ],
      "metadata": {
        "id": "yNwTqOMD4Q_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cascading"
      ],
      "metadata": {
        "id": "yRMJKSOR4gHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the name suggests,\n",
        "- we cascade the models one after other\n",
        "- i.e. chaining of models\n",
        "\n",
        "\n",
        "let's see how it works"
      ],
      "metadata": {
        "id": "XEYhZaNd4iFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say, we are trying to predict whether a transaction is fradulent or not\n",
        "\n"
      ],
      "metadata": {
        "id": "CMsWr8ul4t9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "What will be the nature of dataset for fradulent trascation detection ?\n",
        "\n",
        "a. Balanced dataset\n",
        "b. Imbalanced dataset\n",
        "\n",
        "Correct option: b. Imbalanced data.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "F_eIFlZv-Di0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/312/original/z.png?1705488040' width=700></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "RNz1Sw4Zkxth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let the dataset be $D$ which will be imbalanced, and\n",
        "\n",
        "- $y=1$ for fraudulent transaction\n",
        "- $y =0$ for non fraudulent transaction"
      ],
      "metadata": {
        "id": "U0siK6-Z-TNL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i14u9uSDCg9C"
      },
      "source": [
        "For a query point $x_q$,\n",
        "- we will pass this point through the first model $M_1$\n",
        "- Model $M_1$ will return the probability of the query point being a fraud\n",
        "\n",
        "\n",
        "Based on probability, we'll split it in 2 parts:\n",
        "- if the probability of ŷ  being 1 is extremely low, say $< 0.001$ then\n",
        "    - we consider that as not fraudulent, let this data be $D_1$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/313/original/z.png?1705488064' width=700></center>"
      ],
      "metadata": {
        "id": "pfkZC6psAmYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What happens to rest of the data?\n",
        "\n",
        "The rest of the points ($D-D_1$) i.e. data with prob. > 0.001 which we are not sure about\n",
        "- will be passed through the next model $M_2$\n",
        "- Model $M_2$ will be more stricter i.e. it'll penalize more.\n",
        "\n",
        "Again model $M_2$ will split into 2 parts\n",
        "- non fraud (say, $P(y =1 | x_q) < 0.001$)\n",
        "- fraud transac. (p > 0.001)\n",
        "\n",
        "We can again add another model after $M_2$ which will work on same principles\n"
      ],
      "metadata": {
        "id": "6k2rAX6Z-arB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfzVddDyS_N_"
      },
      "source": [
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/314/original/z.png?1705488089' width=700></center>\n",
        "\n",
        "<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/315/original/z.png?1705488115' width=700></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98Cc_gUP_Vt"
      },
      "source": [
        "#### Did you notice the structure of model?\n",
        "We are cascading/chaining one model after another.\n",
        "\n",
        "In the first model we are just removing all the genuine customers\n",
        "- in second model, we are trying to find the may be fraudalent points from 2nd data set,\n",
        "\n",
        "we contimue doing this **cascading**\n",
        "\n",
        "Every model is trained on different datasets ($D - D_n$ )\n",
        "\n",
        "If even after all these models, we are not sure there will be a human at last to verify the same."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that\n",
        "- cascading is used in industry where\n",
        "    -  loss associated with misclassification is high\n",
        "\n",
        "For example:\n",
        "- cancer detection\n",
        "- financial domain etc"
      ],
      "metadata": {
        "id": "BzXvzEnQ-qyK"
      }
    }
  ]
}