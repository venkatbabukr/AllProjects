# -*- coding: utf-8 -*-
"""7-Notes-Boosting-2-Digital.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YhIOO5LXtNO-EhWRN8ufksK5BNp1bMNs

## Content

- **Internals of GBDT - Pseudo Code**
    - Quiz 1

- **Bias Variance tradeoff**


- **How do we regularize GBDT ?**
    - Regularization by Shrinkage
    - Stochsatic GBDT



- **Does outlier impact GBDT?**



- **Use case - EMG Signal Classification**

## Internals of Gradient Boosting Decision Tree (GBDT) - Pseudo Code

Link: https://en.wikipedia.org/wiki/Gradient_boosting#:~:text=5%5D%5B2%5D-,Input,-%3A%20training%20set

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/272/original/z.png?1705486735' width=700></center>

#### Inputs

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/273/original/z.png?1705486764' width=700></center>

Now, let's start off with the how algo works:

### Step 1

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/274/original/z.png?1705486790' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/275/original/z.png?1705486818' width=800></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/276/original/z.png?1705486844' width=800></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/277/original/z.png?1705486871' width=800></center>

### Step 2

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/278/original/z.png?1705486899' width=700></center>

#### Step 2.1

First off, in order to train new model
- we **calculate** the **residuals of the previous model**

Here, we **use pseudo residuals** i.e. negative gradient as residual.

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/279/original/z.png?1705486928' width=700></center>

#### Step 2.2

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/280/original/z.png?1705486952' width=700></center>

Now we have we have learnt $h_1(x)$,
- we need to find its weight $γ_1$


This is what we do in next step

#### Step 2.3

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/281/original/z.png?1705486976' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/282/original/z.png?1705487000' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/283/original/z.png?1705487029' width=700></center>

This weight will be represented using $γ_m$
- For m = 1, it will be $γ_1$

#### Step 2.4

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/284/original/z.png?1705487055' width=700></center>

### Step 3

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/285/original/z.png?1705487078' width=700></center>

Now that we have learnt how does gradient boosting works

Let's write some code to implement boosting using sklearn

Before that, let's look into hyperparams and their impact on model.

## Bias Variance tradeoff

We learnt about various hyperparam in previous lecture. i.e.

- M (number of base learners)
- Depth


let's try to answer some scenarios related to hyperparam

#### M (number of base learners)

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/286/original/z.png?1705487194' width=700></center>

For example:
- Say we take M = 1
    - i.e. Stage 0 (mean model) and Stage 1 model
    - This model will not have enough base learners to learn from the previous model's error
    - it's predictions will be close to mean value.
    - Hence, it will underfit.

#### Depth

Next, let's look into depth of decision Tree

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/287/original/z.png?1705487223' width=700></center>

Conclusion:
- **If we don't train GBDT properly, it'll overfit**.

So, in order to prevent it from overfitting,
- we introduce another level of regularization

## How do we regularize GBDT ?

### Regularization by Shrinkage

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/288/original/z.png?1705487251' width=800></center>

Note that
- This learning rate is a hyperparam
- i.e. its value is a fixed during the whole training/testing process.



In case, you want to learn more about it, refer wiki: <a href ="https://en.wikipedia.org/wiki/Gradient_boosting#:~:text=the%20training%20data.-,Shrinkage,-%5Bedit%5D">link</a>

#### What happens if learning rate is small ?

When learning rate is small value,
- it'll take as more number of iterations for model to converge
- As the impact of $m^{th}$ model will be reduce significatly.

There is another way to regularize GBDT as well

### Stochastic Gradient Boosting

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/289/original/z.png?1705487281' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/290/original/z.png?1705487306' width=700></center>

sklearn documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html

## Does outlier impact GBDT  ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/291/original/z.png?1705487350' width=700></center>

#### How can we tackle this issue ? (Hint: GBDT's superpower)

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/292/original/z.png?1705487375' width=700></center>

The issue is square increase in loss w.r.t small increase in error value

#### What if we modify the loss function to taper off large loss values ?

This is what **Huber loss** does.

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/293/original/z.png?1705487402' width=700></center>

Other than that,
- we **can** also **use RMSE**
- as it is taking the root of whole value,
    - the loss value won't explode for large error values

Now, that we are done with the concept of GBDT

Let's apply it on one interesting usecase

## UseCase - EMG Signal Classification

#### Problem Statement:
- Your task is to classify these EMG signals into 20 different physical actions
- This will then be used for controlling the robotics arm.

#### What is EMG (ElectroMioGraphy) ?
  - Technique to study electrical signals produced by muscular movement.

#### Dataset
- You have a dataset of EMG signals from 4 subjects/people.

#### How was the data collected ?
  - Subject was asked to perform specific physical actions
  - Signals produced due to that movement were recorded over time.
  - 8 channels were used to record the signals
  - Channels here correspond to muscles\
    For eg: Right-hand bicep
  - Frequency : 10 $ms^{-1}$

Now, lets import some libs at first.

Source: https://archive.ics.uci.edu/ml/datasets/EMG+Physical+Action+Data+Set
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import sklearn

"""#### Extracting data"""

!gdown 1h86M8si2YT-aI4Zec1MeMP_mPYsLPy5F

# x is extract

!unrar x "./emg.rar" "./"

"""#### Visualizing file structure"""

!sudo apt install tree

!tree "./EMG Physical Action Data Set/sub1"

"""Here if you see for subject 1 , we have  sub folders
- aggressive and
- normal

These folders mention the aggresive and normal activities respectively with corresponding log and txt files

We will use txt files


Let's see one of the folder from above
"""

!ls -lrt ./EMG\ Physical\ Action\ Data\ Set/sub1/Aggressive/txt/

"""#### Reading data

Now, let's see what is the data in slapping.txt
"""

!cat ./EMG\ Physical\ Action\ Data\ Set/sub1/Aggressive/txt/Slapping.txt

"""**Key observations**

* We got eight columns of the data which corresponds to eight electrodes
* We are collecting data 10 times per millisecond,
- each row gives the data for every 0.1 millisecond

After this, we perform series of preprocessing on the data

#### Summary of preprocessing

**Preprocessing Post Read**

link: https://colab.research.google.com/drive/1jRl6U-gGxTvT1FHGzMW-5BDAhQ6ON6om?usp=sharing

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/294/original/z.png?1705487436' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/295/original/z.png?1705487460' width=700></center>

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/296/original/z.png?1705487484' width=700></center>

#### Preprocessed Data
"""

import pickle

!gdown 171Yoe_GSapyrmOnD9oBzHWNOD_OnQs0F
!gdown 1hnIlTPW3AMeB69EbeaXCRIrpMVT1Vwmc
!gdown 1nZtB_RtxMg_MgoRczb8UWQX-AEK_l3qE
!gdown 1zLDUErwKdmF-RacOyHEuI_z_46LssQtP


with open('X_train.pickle', 'rb') as handle:
    X_train = pickle.load(handle)

with open('X_test.pickle', 'rb') as handle:
    X_test = pickle.load(handle)

with open('Y_train.pickle', 'rb') as handle:
    y_train = pickle.load(handle)

with open('Y_test.pickle', 'rb') as handle:
    y_test = pickle.load(handle)

"""### Modeling

#### Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier as DTC
from sklearn import tree
from sklearn.model_selection import GridSearchCV

params = {
    "max_depth" : [3, 5, 7, 10, 15],
    "max_leaf_nodes" : [20, 40, 60]
}

model1 = DTC()
clf = GridSearchCV(model1, params, scoring = "accuracy", cv=5)

clf.fit(X_train, y_train)

"""Lets see the results of our GridSearch"""

res = clf.cv_results_

for i in range(len(res["params"])):
  print(f"Parameters:{res['params'][i]} Mean_score: {res['mean_test_score'][i]} Rank: {res['rank_test_score'][i]}")

"""#### So whats the best estimator and score ?"""

print(clf.best_estimator_)

clf = DTC(**clf.best_params_)

clf.fit(X_train, y_train)

"""##### Train score"""

clf.score(X_train, y_train)

"""##### Test score

"""

clf.score(X_test, y_test)

"""#### RF"""

from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn import tree
from sklearn.model_selection import RandomizedSearchCV
import datetime as dt

params = {
    "n_estimators": [10,25,50,100,150,200],
    "max_depth" : [3, 5, 10, 15, 20],
    "max_leaf_nodes" : [20, 40, 80]
}

rfc = RFC(n_jobs = -1)
clf = RandomizedSearchCV(rfc, params, scoring = "accuracy", cv=3, n_jobs = -1, verbose = 1)

start = dt.datetime.now()
clf.fit(X_train, y_train)
end = dt.datetime.now()

res = clf.cv_results_

for i in range(len(res["params"])):
  print(f"Parameters:{res['params'][i]} Mean_score: {res['mean_test_score'][i]} Rank: {res['rank_test_score'][i]}")

"""Notice that,

The performance of RF (0.89) is better than DT (0.81)
"""

print(f"Time taken for fits : {end - start}")

print(clf.best_estimator_)

rf = clf.best_estimator_

rf.fit(X_train, y_train)

print("Model acc",rf.score(X_test, y_test))

"""#### GBDT"""

params = {
    "n_estimators": [50,100,150,200],
    "max_depth" : [3, 4, 5, 7],
    "max_leaf_nodes" : [20, 40, 80],
    "learning_rate": [0.1, 0.2, 0.3]
}

from sklearn.ensemble import GradientBoostingClassifier as GBC
from sklearn.model_selection import RandomizedSearchCV
import datetime as dt


gbc = GBC()
clf = RandomizedSearchCV(gbc, params, scoring = "accuracy", cv=3, n_jobs = -1, verbose = 1)

start = dt.datetime.now()

clf.fit(X_train, y_train)

end = dt.datetime.now()

res = clf.cv_results_

for i in range(len(res["params"])):
  print(f"Parameters:{res['params'][i]} Mean_score: {res['mean_test_score'][i]} Rank: {res['rank_test_score'][i]}")

print(f"Time taken for fits : {end - start}")

print(clf.best_estimator_)

gbc = clf.best_estimator_

gbc.fit(X_train, y_train)

print("Model acc",gbc.score(X_test, y_test))

"""Notice that
- It took us > 30 mins to hyperparam tune sklearn GBDT  (slow)
- Test accuracy: 0.96 (better than RF)
"""