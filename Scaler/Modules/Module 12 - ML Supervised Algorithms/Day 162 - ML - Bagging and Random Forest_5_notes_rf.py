# -*- coding: utf-8 -*-
"""5-Notes-RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17xW6ayI5YOOGOyDBxsiUnaU0ORXwJZGN

# Content

- What are Ensemble Models?
- Types of Ensembles
- What is Bagging?

- Ensembling DTs - Random Forest
- How to introduce randomness?
- How to combine multiple DTs?

- How to validate RFs?
- OOB Score

- Bias Variance tradeoff
- Training a RF model
- RF Code Implementation
- Hyperparameters of RF

- Tuning the Hyperparameters (GridSearchCV)

- How to compute Feature Importances?

### Problem Statement:

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/160/original/z.png?1705478105' width='800'>
"""

import pandas as pd
import numpy as np

!gdown 16KtxSt_QEGQvfluEaMls5cCHPwhRXgCk
!gdown 19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk
!gdown 1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF
!gdown 1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK
!gdown 12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG

import pickle
# Load data (deserialize)
with open('preprocessed_X_sm.pickle', 'rb') as handle:
    X_train = pickle.load(handle)

with open('X_test.pickle', 'rb') as handle:
    X_test = pickle.load(handle)

with open('y_sm.pickle', 'rb') as handle:
    y_train = pickle.load(handle)

with open('y_test.pickle', 'rb') as handle:
    y_test = pickle.load(handle)

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(random_state=7, max_depth=4)
tree_clf.fit(X_train, y_train)

print("Train accuracy: {:.2f}".format(tree_clf.score(X_train, y_train)*100))
print("Test accuracy: {:.2f}".format(tree_clf.score(X_test, y_test)*100))

"""<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/161/original/z.png?1705478143' width='800'>

### What are Ensembles?

Till now we have learned about different kinds of models.

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/162/original/z.png?1705478174' width='800'>

\
This is the key principle of ensembles.

### Types of Ensembles

There are mainly 4 types of ensemble learning techniques -

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/163/original/z.png?1705478211' width='800'>

### What is Bagging?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/164/original/z.png?1705478240' width='800'>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/165/original/z.png?1705478269' width='800'>

### Random Forest

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/167/original/z.png?1705478308' width='800'>

### Combining Decision Trees

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/168/original/z.png?1705478337' width='800'>

### Randomness in model

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/169/original/z.png?1705478368' width='800'>

### Validating RF

After training, we cross validate each and every base learner.

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/170/original/z.png?1705478396' width='800'>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/171/original/z.png?1705478423' width='800'>

### Overall Performance

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/172/original/z.png?1705478474' width='800'>

### OOB Score

We use the left over,
- ($n-m$) Out of Bag datapoints
- to calculate the **OOB score**.

#### Calculating OOB Score

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/173/original/z.png?1705478504' width='800'>

#### Using OOB Score

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/174/original/z.png?1705478535' width='800'>

### Bias Variance Tradeoff

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/175/original/z.png?1705478562' width='800'>

### Reducing Variance

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/176/original/z.png?1705478587' width='800'>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/177/original/z.png?1705478613' width='800'>

### Training a RF model

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/178/original/z.png?1705478642' width='800'>

### Code Implementation - RF

Let's try to train a RF classifier for our problem.
"""

# Load data (deserialize)

with open('preprocessed_X_sm.pickle', 'rb') as handle:
    X = pickle.load(handle)

with open('y_sm.pickle', 'rb') as handle:
    y = pickle.load(handle)

from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(random_state=7, max_depth=4, n_estimators=100)

from sklearn.model_selection import KFold, cross_validate

kfold = KFold(n_splits=10)
cv_acc_results = cross_validate(rf_clf, X, y, cv=kfold, scoring='accuracy', return_train_score=True)

print(f"K-Fold Accuracy Mean: \n Train: {cv_acc_results['train_score'].mean()*100:.2f} \n Validation: {cv_acc_results['test_score'].mean()*100:.2f}")
print(f"K-Fold Accuracy Std: \n Train: {cv_acc_results['train_score'].std()*100:.2f}, \n Validation: {cv_acc_results['test_score'].std()*100:.2f}")

"""As we can see that,
- the test accuracy has increased
- From **78%** to **84%**

### Optimizing RF

Remember hyperparameters?

Let's see the various hyperparameters of Random Forest.

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/179/original/z.png?1705478677' width='800'>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/183/original/z.png?1705478706' width='800'>

Similar to $Î»$,
- which we used in linear & logistic regression
- for regularization.

\
<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/185/original/z.png?1705478734' width='800'>

There are other hyperparameters too in a RF.

Most of them are same ones that we saw in DT.

https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/186/original/z.png?1705478763'  width='800'>

```
QUIZ:

Which one of the following in not a hyperparameter of Random Forest?

A. Number of base learners
B. Depth of base learners
C. Sample size
D. Total number of columns

ANS: D. Total number of columns
```

```
QUIZ:

What is the use of the hyperparameter 'ccp_alpha'?

A. To set the column sampling ratio
B. To control underfitting or overfitting
C. To optimize the learning rate of RF
D. To set the depth of the base learners

ANS: B. To control underfitting or overfitting
```

### Hyperparameter Tuning

#### Grid Search

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/190/original/z.png?1705478925' width='800'>
"""

# Defining parameters -

params = {
          'n_estimators' : [100,200,300,400],
          'max_depth' : [3,5,10],
          'criterion' : ['gini', 'entropy'],
          'bootstrap' : [True, False],
          'max_features' : [8,9,10]
         }

from sklearn.model_selection import GridSearchCV

grid = GridSearchCV(estimator = RandomForestClassifier(),
                    param_grid = params,
                    scoring = 'accuracy',
                    cv = 3,
                    n_jobs=-1
                    )

grid.fit(X, y)

print("Best params: ", grid.best_params_)
print("Best score: ", grid.best_score_)

clf2 = RandomForestClassifier(random_state=7, bootstrap=False, criterion='gini',
                              max_depth=10, max_features=8, n_estimators=200)

kfold = KFold(n_splits=10)
cv_acc_results = cross_validate(clf2, X, y, cv=kfold, scoring='accuracy', return_train_score=True)

print(f"K-Fold Accuracy Mean: \n Train: {cv_acc_results['train_score'].mean()*100:.3f} \n Validation: {cv_acc_results['test_score'].mean()*100:.3f}")
print(f"K-Fold Accuracy Std: \n Train: {cv_acc_results['train_score'].std()*100:.3f}, \n Validation: {cv_acc_results['test_score'].std()*100:.3f}")

"""#### Randomized Search

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/187/original/z.png?1705478796' width='800'>

Let's try finding the optimal value of `ccp_alpha` for our model.
"""

# Defining parameters -

from scipy.stats import uniform

params = {'ccp_alpha': uniform(loc=0, scale=0.4)}
# sample from uniform dist between 0 to 0.4

from sklearn.model_selection import RandomizedSearchCV

random = RandomizedSearchCV(estimator = RandomForestClassifier(random_state=7, bootstrap=False, criterion='gini',
                                                               max_depth=10, max_features=8, n_estimators=200),
                            param_distributions = params,
                            scoring = 'accuracy',
                            cv = 3,
                            n_iter=15,
                            n_jobs=-1
                            )

random.fit(X, y)

print("Best param: ", random.best_params_)
print("Best score: ", random.best_score_)

"""### Computing Feature Importance

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/062/188/original/z.png?1705478846' width='800'>
"""

# Feature Importance

import matplotlib.pyplot as plt

rf_clf.fit(X, y)
importances = rf_clf.feature_importances_

indices = np.argsort(importances)[::-1] # Sort feature importances in descending order
names = [X.columns[i] for i in indices] # Rearrange feature names so they match the sorted feature importances

plt.figure(figsize=(15, 7)) # Create plot
plt.title("Feature Importance") # Create plot title
plt.bar(range(X.shape[1]), importances[indices]) # Add bars
plt.xticks(range(X.shape[1]), names, rotation=90) # Add feature names as x-axis labels
plt.show() # Show plot

