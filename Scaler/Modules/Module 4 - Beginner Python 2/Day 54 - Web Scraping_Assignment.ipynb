{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "$\\newcommand{\\trinom}[3]{\\begin{pmatrix} #1 \\\\ #2 \\\\ #3 \\end{pmatrix}}$"
      ],
      "metadata": {
        "id": "7kTvDjuadqn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1. Get the element**\n",
        "\n",
        "Using Beautiful Soup in Python, which one-liner code will find the first <h2> tag in the following HTML structure?\n",
        "\n",
        "HTML Structure:\n",
        "\n",
        "```html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>My Web Page</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Welcome to My Web Page</h1>\n",
        "    <div class=\"header\">\n",
        "        <h2>News</h2>\n",
        "        <p>Latest news will be displayed here</p>\n",
        "    </div>\n",
        "    <div class=\"content\">\n",
        "        <h2>Hello</h2>\n",
        "        <p>This is some content on my webpage.</p>\n",
        "        <ul>\n",
        "            <li>Point 1</li>\n",
        "            <li>Point 2</li>\n",
        "            <li>Point 3</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    <div class=\"footer\">\n",
        "        <p>Contact us at contact@example.com</p>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1. soup.find('h2')\n",
        "2. soup.find_all('h2')[0]\n",
        "3. soup.body.h2\n",
        "4. All of the above"
      ],
      "metadata": {
        "id": "ANuD_mYtti85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Option 4. All of the above"
      ],
      "metadata": {
        "id": "MsCTl_X6hJ98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2. finding all**\n",
        "\n",
        "What is the output of the given below Python code?\n",
        "\n",
        "**Python Code:**\n",
        "\n",
        "```python\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Sample Page</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"info\">\n",
        "        <p>First Paragraph</p>\n",
        "        <p class=\"highlight\">Second Paragraph</p>\n",
        "        <p>Third Paragraph</p>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "result = soup.find_all('p', class_='highlight')\n",
        "print(result)\n",
        "```"
      ],
      "metadata": {
        "id": "zpPTjWZOud3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Sample Page</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"info\">\n",
        "        <p>First Paragraph</p>\n",
        "        <p class=\"highlight\">Second Paragraph</p>\n",
        "        <p>Third Paragraph</p>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "result = soup.find_all('p', class_='highlight')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF4erwo9cb-X",
        "outputId": "1d1a11af-4029-41e1-82ff-10dae9dcc9fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<p class=\"highlight\">Second Paragraph</p>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q3. understanding robots.txt**\n",
        "\n",
        "Which of the following statements best describes the importance of checking a website's `robots.txt` file before performing web scraping?\n",
        "\n",
        "1. The robots.txt file contains the necessary passwords and credentials required for web scraping.\n",
        "2. It is important to check the robots.txt file because it lists the data types that can be legally scraped from the website.\n",
        "3. The robots.txt file indicates which parts of the website the owner prefers not to be accessed by web crawlers, making it crucial for ethical web scraping.\n",
        "4. Checking the robots.txt file is not necessary for web scraping as it only pertains to search engine optimization.\n"
      ],
      "metadata": {
        "id": "CK8d0jhCvKPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Option 3: The robots.txt file indicates which parts of the website the owner prefers not to be accessed by web crawlers, making it crucial for ethical web scraping."
      ],
      "metadata": {
        "id": "q3vQEAtIvZvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q4. finding all tags**\n",
        "\n",
        "HTML Structure:\n",
        "\n",
        "```html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>News Portal</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"main-content\">\n",
        "        <p>Paragraph 1 in main content.</p>\n",
        "        <p>Paragraph 2 in main content.</p>\n",
        "    </div>\n",
        "    <div id=\"sidebar\">\n",
        "        <p>Paragraph in sidebar.</p>\n",
        "    </div>\n",
        "    <div>\n",
        "        <p>Paragraph in a div without an ID.</p>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "Using Beautiful Soup in Python, which one-liner code will find all the `<p>` tags within the `<div>` element having the ID `main-content` in the above HTML structure?"
      ],
      "metadata": {
        "id": "U0RbXV2pvoJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "```python\n",
        "soup.find('div', id='main-content').find_all('p')\n",
        "```"
      ],
      "metadata": {
        "id": "-IR_kF9v4Zi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q5. scrape the output**\n",
        "\n",
        "What is the output of the given below Python code?\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "```python\n",
        "html_doc = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Book Store</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"bestsellers\">\n",
        "        <h2>Best Selling Books</h2>\n",
        "        <ul>\n",
        "            <li><a href=\"/book1\">The Great Gatsby</a></li>\n",
        "            <li><a href=\"/book2\">To Kill a Mockingbird</a></li>\n",
        "            <li><a href=\"/book3\">1984</a></li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    <div id=\"new-releases\">\n",
        "        <h2>New Releases</h2>\n",
        "        <ul>\n",
        "            <li><a href=\"/book4\">The Testaments</a></li>\n",
        "            <li><a href=\"/book5\">Normal People</a></li>\n",
        "        </ul>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "titles = [a.get_text() for a in soup.find_all('a')]\n",
        "print(titles)\n",
        "```"
      ],
      "metadata": {
        "id": "e0Y8F_HZmzs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_doc = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Book Store</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"bestsellers\">\n",
        "        <h2>Best Selling Books</h2>\n",
        "        <ul>\n",
        "            <li><a href=\"/book1\">The Great Gatsby</a></li>\n",
        "            <li><a href=\"/book2\">To Kill a Mockingbird</a></li>\n",
        "            <li><a href=\"/book3\">1984</a></li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    <div id=\"new-releases\">\n",
        "        <h2>New Releases</h2>\n",
        "        <ul>\n",
        "            <li><a href=\"/book4\">The Testaments</a></li>\n",
        "            <li><a href=\"/book5\">Normal People</a></li>\n",
        "        </ul>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "titles = [a.get_text() for a in soup.find_all('a')]\n",
        "print(titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_1JLBzJeg-2",
        "outputId": "531dcb1c-11e6-4c45-b1d8-f02cf9621970"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Great Gatsby', 'To Kill a Mockingbird', '1984', 'The Testaments', 'Normal People']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AQ1. scraping the table**\n",
        "\n",
        "Given following the HTML structure of a website, complete the python function that takes this html structure as a string variable html_content and scrape the content of table from it and return in the form of Python 2D list as show in output sample.\n",
        "\n",
        "**HTML Structure**\n",
        "\n",
        "```html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Product Data</title>\n",
        "</head>\n",
        "<body>\n",
        "    <table>\n",
        "        <thead>\n",
        "            <tr>\n",
        "                <th>Product Name</th>\n",
        "                <th>Price</th>\n",
        "                <th>Category</th>\n",
        "            </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "            <tr>\n",
        "                <td>Laptop</td>\n",
        "                <td>999</td>\n",
        "                <td>Electronics</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td>Smartwatch</td>\n",
        "                <td>250</td>\n",
        "                <td>Wearables</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td>Novel</td>\n",
        "                <td>15.99</td>\n",
        "                <td>Books</td>\n",
        "            </tr>\n",
        "        </tbody>\n",
        "    </table>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "**Output Sample**\n",
        "\n",
        "```python\n",
        "[['Product Name', 'Price', 'Category'],\n",
        " ['Laptop', '999', 'Electronics'],\n",
        " ['Smartwatch', '250', 'Wearables'],\n",
        " ['Novel', '15.99', 'Books']]\n",
        " ```"
      ],
      "metadata": {
        "id": "ghV8A9rpoeot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_table(html_content):\n",
        "  # write your code here\n",
        "  soup = BeautifulSoup(html_content, 'html.parser')\n",
        "  table = soup.find('table')\n",
        "  table_data = []\n",
        "  header_row = table.find('thead').find('tr')\n",
        "  header_data = [th.get_text(strip=True) for th in header_row.find_all('th')]\n",
        "  table_data.append(header_data)\n",
        "  body_rows = table.find('tbody').find_all('tr')\n",
        "  for row in body_rows:\n",
        "    row_data = [td.get_text(strip=True) for td in row.find_all('td')]\n",
        "    table_data.append(row_data)\n",
        "  return table_data\n",
        "\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Product Data</title>\n",
        "</head>\n",
        "<body>\n",
        "    <table>\n",
        "        <thead>\n",
        "            <tr>\n",
        "                <th>Product Name</th>\n",
        "                <th>Price</th>\n",
        "                <th>Category</th>\n",
        "            </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "            <tr>\n",
        "                <td>Laptop</td>\n",
        "                <td>999</td>\n",
        "                <td>Electronics</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td>Smartwatch</td>\n",
        "                <td>250</td>\n",
        "                <td>Wearables</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td>Novel</td>\n",
        "                <td>15.99</td>\n",
        "                <td>Books</td>\n",
        "            </tr>\n",
        "        </tbody>\n",
        "    </table>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "table_data = scrape_table(html_content)\n",
        "print(table_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKfq7G_XK4ZY",
        "outputId": "f120ce68-7e80-4acf-9a86-84229c39e188"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Product Name', 'Price', 'Category'], ['Laptop', '999', 'Electronics'], ['Smartwatch', '250', 'Wearables'], ['Novel', '15.99', 'Books']]\n"
          ]
        }
      ]
    }
  ]
}