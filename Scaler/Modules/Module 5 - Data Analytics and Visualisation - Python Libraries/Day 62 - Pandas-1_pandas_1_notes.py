# -*- coding: utf-8 -*-
"""Pandas-1 notes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t7JsCfKIHRWPDNnaGOMJzkrrRpbJdbiq

# Pandas 1

---

## Content

- Introduction to Pandas
- DataFrame & Series
- Creating DataFrame from Scratch (Post-read)
- Basic ops on a DataFrame
- Basic ops on Columns
    - Accessing column(s)
    - Check for unique values
    - Rename column
    - Deleting column(s)
    - Creating new column(s)
- Basic ops on Rows
    - Implicit/Explicit index
    - Indexing in Series
    - Slicing in Series
        - loc/iloc
    - Indexing/Slicing in DataFrame

---

## **Introduction to Pandas**

### Pandas Installation
"""

# !pip install pandas

"""### Importing Pandas

- You should be able to import Pandas after installing it.
- We'll import `pandas` using its **alias name `pd`**.
"""

import pandas as pd
import numpy as np

"""### Why use Pandas?

- The major **limitation of numpy** is that it can only work with one datatype at a time.
- Most real-world datasets contain a mix of different datatypes.
  - **names of a place would be string**
  - **population of a place would be int**
  
It is difficult to work with data having **heterogeneous values** using Numpy.

On the other hand, Pandas can work with numbers and strings together.

### Problem Statement

- Imagine that you are a Data Scientist with McKinsey.
- McKinsey wants to understand the relation between GDP per capita and life expectancy for their clients.
- The company has obtained data from various surveys conducted in different countries over several years.
- The acquired data includes information on
  - Country
  - Population Size
  - Life Expectancy
  - GDP per Capita
- We have to analyse the data and draw inferences that are meaningful to the company.

### Loading the dataset

Dataset: https://drive.google.com/file/d/1E3bwvYGf1ig32RmcYiWc0IXPN-mD_bI_/view?usp=sharing
"""

!wget "https://drive.google.com/uc?export=download&id=1E3bwvYGf1ig32RmcYiWc0IXPN-mD_bI_" -O mckinsey.csv

"""**Now how should we read this dataset?**

Pandas makes it very easy to work with these kinds of files.
"""

df = pd.read_csv('mckinsey.csv') # storing the data in df
df

"""---

### DataFrame and Series

**What can we observe from the above dataset?**

We can see that it has:
- 6 columns
- 1704 rows

**What do you think is the datatype of `df` ?**
"""

type(df)

"""It is a **Pandas DataFrame**

#### What is a Pandas DataFrame?

- A DataFrame is a **table-like (structured)** representation of data in Pandas.
- Considered as a **counterpart of 2D matrix** in Numpy.

<img src="https://drive.google.com/uc?id=1urINAXwrx9Fg5cgm5yxtUKqcYV7_qViZ">

**How can we access a column, say `country` of the dataframe?**
"""

df["country"]

"""As you can see, we get all the values present in the **country** column.

**What is the data-type of a column?**
"""

type(df["country"])

"""It is a **Pandas Series**

#### What is a Pandas Series?
- A **Series** in Pandas is what a **Vector** is in Numpy.

**What exactly does that mean?**
- It means that a Series is a **single column of data**.
- Multiple Series are stacked together to form a DataFrame.

<img src="https://drive.google.com/uc?id=1y1DPzrethqr7DDomwxbDtt3ti7vTU7s8">

Now we have understood what Series and DataFrame are.

**How can we find the datatype, name, total entries in each column?**
"""

df.info()

"""`df.info()` gives a list of columns with:

- **Name** of columns
- **How many non-null values (blank cells)** each column has.
- **Type of values** in each column - int, float, etc.

**By default**, it shows **Dtype** as `object` for anything other than **int or float**.

**What if we want to see the first few rows in the dataset?**
"""

df.head()

"""**`df.head()` prints the top 5 rows by default.**

We can also pass in number of rows that we want to see.

"""

df.head(10)

"""Similarly, we can use **`df.tail()` if we wish to see the last few rows**."""

df.tail()

"""**How can we find the shape of a dataframe?**"""

df.shape

"""Similar to Numpy, it gives the **no. of rows and columns**.

### Post-read

- [DataFrame from Scratch](https://colab.research.google.com/drive/1x3ct95RtIIQTJeGbyuuYaMociVp90ww6?usp=sharing)

---

## **Basic operations on Columns**

**What operations can we do using columns?**

- Add a column
- Delete a column
- Rename a column

We can see that our dataset has 6 columns.

**How can we get the names of all these cols?**

We can do it in two ways:
1. `df.columns`
2. `df.keys`
"""

df.columns  # using attribute `columns` of dataframe

df.keys()  # using method `keys()` of dataframe

"""**Note:**
- Here, `Index` is a type of Pandas class used to store the `address` of the series/dataframe.
- It is an immutable sequence used for indexing.

**How can we access these columns?**
"""

df['country'].head()  # accessing a single column

df[['country', 'life_exp']].head() # accessing multiple columns

"""**And what if we pass a single column name?**"""

df[['country']].head()

"""**Note:**
- Notice how this output type is different from our earlier output using `df['country']`
- `['country']` gives a Series while `[['country']]` gives a DataFrame.

**How can we find the countries that have been surveyed?**

We can find the unique values in the `country` column.
"""

df['country'].unique()

"""**What if you also want to check the count of occurence of each country in the dataframe?**"""

df['country'].value_counts()

"""**Note:** `value_counts()` shows the output in **decreasing order of frequency**.

**What if we want to change the name of a column?**

We can rename the column by
- passing the dictionary with `old_name:new_name` pair
- specifying `axis=1`
"""

df.rename({"population": "Population", "country":"Country" }, axis = 1)

"""Alternatively, we can also rename the column
- without specifying `axis`
- by using the `column` parameter


"""

df.rename(columns={"country":"Country"})

"""If we try and check the original dataframe `df` -"""

df

"""We can clearly see that the column names are still the same and have not changed.

The changes doesn't happen in original dataframe unless we specify a parameter called `inplace` as True.
"""

df.rename({"country": "Country"}, axis = 1, inplace = True)
df

"""**Note**
- `.rename` has default value of axis=0
- If two columns have the **same name**, then `df['column']` will display both columns.

There's another way of accessing the column values.
"""

df.Country

"""This however doesn't work everytime.

**What do you think could be the problem here?**

- If the column names are **not strings**
  - Starting with **number**: e.g. `2nd`
  - Contains a **whitespace**: e.g. `Roll Number`
- If the column names conflict with **methods of the DataFrame**
  - e.g. `shape`

We already know the continents in which each country lies.

So we probably don't need this column.

**How can we delete columns from a dataframe?**
"""

df.drop('continent', axis=1)

"""The `drop()` function takes two parameters:
- column name
- axis
  
By default, the value of `axis` is 0.

An alternative to the above approach is using the "columns" parameter as we did in `rename()`.
"""

df.drop(columns=['continent'])

"""As you can see, the column `contintent` is dropped.

**Has the column been permanently deleted?**
"""

df.head()

"""No, the column `continent` is still there in the original dataframe.

**Do you see what's happening here?**

We only got a **view of dataframe** with column `continent` dropped.

**How can we permanently drop the column?**

- We can either **re-assign** it `df = df.drop('continent', axis=1)`   
- Or we can **set the parameter `inplace=True`**
  - By default, `inplace=False`.
"""

df.drop('continent', axis=1, inplace=True)

"""**What if we want to create a new column?**

- We can either use values from **existing columns**.
- Or we can create our own values.

**How to create a column using values from an existing column?**
"""

df["year+7"] = df["year"] + 7
df.head()

"""As we see, a new column `year+7` is created from the column `year`.

We can also use values from two columns to form a new column.

**Which two columns can we use to create a new column `gdp`?**
"""

df['gdp'] = df['gdp_cap'] * df['population']
df.head()

"""As you can see
- An additional column has been created.
- Values in this column are **product of respective values in `gdp_cap` and `population` columns**.

**What other operations we can use?**

- Addition
- Subtraction
- Division

**How can we create a new column from our own values?**

- We can either **create a list**.
- Or we can **create a Pandas Series** from a list/numpy array for our new column.
"""

df["Own"] = [i for i in range(1704)]  # count of these values should be correct
df

"""Before we move to ops on rows, let's drop the newly created columns."""

df.drop(columns=["Own",'gdp', 'year+7'], axis = 1, inplace = True)
df

"""---

## **Basic operations on Rows**

**Just like columns, do rows also have labels? Yes.**

- **Can we change row labels (like we did for columns)?**
- **What if we want to start indexing from 1 (instead of 0)?**
"""

df.index = list(range(1, df.shape[0]+1)) # create a list of indices of same length
df

"""As you can see the indexing now starts from 1 instead of 0.

### Explicit & Implicit Indices

**What are these row labels/indices exactly?**
  
- They can be called identifiers of a particular row.
- Specifically known as **explicit indices**.

**Additionally, can a series/dataframe also use Python style indexing? Yes.**

- The Python style indices are known as **implicit indices**.

**How can we access explicit index of a particular row?**
- using `df.index[]`
- Takes **impicit index** of row to give its **explicit index**.
"""

df.index[1] # implicit index 1 gave explicit index 2

"""**But why not use just implicit indexing?**

Explicit indices can be changed to any value of any datatype.
- e.g. explicit index of 1st row can be changed to `first`
- Or something like a floating point value, say `1.0`
"""

df.index = np.arange(1, df.shape[0]+1, dtype='float')
df

"""As we can see, the indices are now floating point values.

Now to understand string indices, let's take a small subset of our original dataframe.
"""

sample = df.head()
sample

"""**What if we want to use string indices?**"""

sample.index = ['a', 'b', 'c', 'd', 'e']
sample

"""This shows us that we can use almost anything as our explicit index.

Now, let's reset our indices back to integers.
"""

df.index = np.arange(1, df.shape[0]+1, dtype='int')

"""**What if we want to access any particular row (say first row)?**

Let's first see for one column.

Later, we can generalise the same for the entire dataframe.
"""

ser = df["Country"]
ser.head(20)

"""We can simply use its indices much like we do in a Numpy array.

**So, how will be then access the 13th element?**
"""

ser[12]

"""**What about accessing a subset of rows (say 6th to 15th)?**"""

ser[5:15]

"""This is known as `Slicing`.

Notice something different though?

- **Indexing in Series** used **explicit indices**
- **Slicing** however used **implicit indices**

Let's try the same for the dataframe.

**How can we access a row in a dataframe?**
"""

df[0]

"""Notice that this syntax is exactly same as how we tried accessing a column.

- `df[x]` looks for column with name `x`

**How can we access a slice of rows in the dataframe?**
"""

df[5:15]

"""Woah, so the slicing works.

This can be a cause for confusion.

To avoid this, Pandas provides special indexers, `loc` and `iloc`

## **loc and iloc**

### **1. loc**

- Allows indexing and slicing that always references the explicit index.
"""

df.loc[1]

df.loc[1:3]

"""Did you notice something strange here?

- The **range is inclusive** of **end point** for `loc`.
- **Row with label 3** is **included** in the result.

### **2. iloc**

- Allows indexing and slicing that always references the implicit index.
"""

df.iloc[1]

"""**Will `iloc` also consider the range inclusive?**"""

df.iloc[0:2]

"""No, because **`iloc` works with implicit Python-style indices**.

**Which one should we use?**
- Generally, explicit indexing is considered to be better than implicit indexing.
- But it is recommended to always use both `loc` and `iloc` to avoid any confusions.

**What if we want to access multiple non-consecutive rows at same time?**
"""

df.iloc[[1, 10, 100]]

"""We can just **pack the indices in `[]`** and pass it in `loc` or `iloc`.

**What about negative index? Which would work between `iloc` and `loc`?**
"""

df.iloc[-1]

# Works and gives last row in dataframe

df.loc[-1]

# Does not work

"""**So, why did `iloc[-1]` worked, but `loc[-1]` didn't?**

- Because **`iloc` works with positional indices, while `loc` with assigned labels**.
- `[-1]` here points to the **row at last position** in `iloc`.

**Can we use one of the columns as row index?**
"""

temp = df.set_index("Country")
temp

"""**Note:**
In earlier versions of Pandas, `drop=True` has to be provided to delete the column being used as new index.

**Now what would the row corresponding to index `Afghanistan` give?**
"""

temp.loc['Afghanistan']

"""As you can see, we got the rows all having index `Afghanistan`.

Generally, it is advisable to keep unique indices. But it also depends on the use-case.

**How can we reset our indices back to integers?**
"""

df.reset_index()

"""Notice that it's creating a new column `index`.

**How can we reset our index without creating this new column?**
"""

df.reset_index(drop=True) # by using drop=True we can prevent creation of a new column

"""Great!

Now let's do this in place.
"""

df.reset_index(drop=True, inplace=True)

"""---"""