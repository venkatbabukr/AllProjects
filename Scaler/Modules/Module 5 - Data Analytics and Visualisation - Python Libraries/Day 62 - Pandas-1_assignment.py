# -*- coding: utf-8 -*-
"""Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F9YR2xL3cGauDssWmcJ1XNPiJG0MplfT

$\newcommand{\trinom}[3]{\begin{pmatrix} #1 \\ #2 \\ #3 \end{pmatrix}}$

# **Q1. First 20**

Which of the following options will return the first 20 rows of a given dataframe **df**?

1. df.head()
2. df.head(20)
3. df.tail(20)
4. df.iloc[:20]

#### **Ans:**

Options 2 & 4:
* df.head(20)
* df.iloc[:20]

**Explanation:** See code below
"""

import pandas as pd
import numpy as np

df = pd.DataFrame(np.arange(300).reshape(30, 10))
print(df.head(20))
print(df.iloc[:20])

"""# **Q2. Be unique**

Which of the following statements are true?

1. .unique() method returns unique values in a Series.
2. .unique(), when applied on a dataframe returns unique values for each column.
3. .nunique() method returns the count of unique elements in a Series.
4. .nunique(), when applied on a dataframe returns the number of unique elements for each column.

#### **Ans:**

Options 1, 3 & 4

* .unique() method returns unique values in a Series.
* .nunique() method returns the count of unique elements in a Series.
* .nunique(), when applied on a dataframe returns the number of unique elements for each column.

**Explanation:** See code below
"""

import pandas as pd
import numpy as np
import json

df_num_cols = 10
df_num_rows = 15
dfcols = list(chr(ord('A') + i) for i in range(df_num_cols))
df = pd.DataFrame(
    np.random.randint(0,
        df_num_rows * df_num_cols,
        size=(df_num_rows, df_num_cols)),
    columns=dfcols)
print(f"""
Data sample:
{df}
""")
uniques = [
    {
      'col': col,
      # 'unique_count': df[col].nunique(),
      'unique_values': str(df[col].unique().tolist())
    } for col in df.columns]

print(f"""
Uniques output:
{json.dumps(uniques, indent = 2)}

Total uniques in df:
{df.nunique()}
""")

"""# **Q3. Data Extraction**

Given the following csv data, which of the following command(s) is/are the **correct** way to extract the mentioned columns in the order: **time, total_bill, tip**?

**Options:**
1. pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])
2. df[['time', 'total_bill', 'tip']]
3. df.loc[:, ['time', 'total_bill', 'tip']]
4. df.iloc[:,0:2]

#### **Ans:***

Options 1, 2, & 3
* pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])
* df[['time', 'total_bill', 'tip']]
* df.loc[:, ['time', 'total_bill', 'tip']]
"""

# Use this if you want to download data from Google drive
# !wget https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/276/original/tips.csv?1645193273 -O tips.csv
# df = pd.read_csv('tips.csv')

q3_csv_data = '''
total_bill,tip,sex,smoker,day,time,size
16.99,1.01,Female,No,Sun,Dinner,2
10.34,1.66,Male,No,Sun,Dinner,3
21.01,3.5,Male,No,Sun,Dinner,3
23.68,3.31,Male,No,Sun,Dinner,2
24.59,3.61,Female,No,Sun,Dinner,4
25.29,4.71,Male,No,Sun,Dinner,4
8.77,2.0,Male,No,Sun,Dinner,2
26.88,3.12,Male,No,Sun,Dinner,4
15.04,1.96,Male,No,Sun,Dinner,2
14.78,3.23,Male,No,Sun,Dinner,2
10.27,1.71,Male,No,Sun,Dinner,2
35.26,5.0,Female,No,Sun,Dinner,4
15.42,1.57,Male,No,Sun,Dinner,2
18.43,3.0,Male,No,Sun,Dinner,4
14.83,3.02,Female,No,Sun,Dinner,2
21.58,3.92,Male,No,Sun,Dinner,2
10.33,1.67,Female,No,Sun,Dinner,3
16.29,3.71,Male,No,Sun,Dinner,3
16.97,3.5,Female,No,Sun,Dinner,3
20.65,3.35,Male,No,Sat,Dinner,3
17.92,4.08,Male,No,Sat,Dinner,2
20.29,2.75,Female,No,Sat,Dinner,2
15.77,2.23,Female,No,Sat,Dinner,2
39.42,7.58,Male,No,Sat,Dinner,4
19.82,3.18,Male,No,Sat,Dinner,2
17.81,2.34,Male,No,Sat,Dinner,4
13.37,2.0,Male,No,Sat,Dinner,2
12.69,2.0,Male,No,Sat,Dinner,2
21.7,4.3,Male,No,Sat,Dinner,2
19.65,3.0,Female,No,Sat,Dinner,2
9.55,1.45,Male,No,Sat,Dinner,2
18.35,2.5,Male,No,Sat,Dinner,4
15.06,3.0,Female,No,Sat,Dinner,2
20.69,2.45,Female,No,Sat,Dinner,4
17.78,3.27,Male,No,Sat,Dinner,2
24.06,3.6,Male,No,Sat,Dinner,3
16.31,2.0,Male,No,Sat,Dinner,3
16.93,3.07,Female,No,Sat,Dinner,3
18.69,2.31,Male,No,Sat,Dinner,3
31.27,5.0,Male,No,Sat,Dinner,3
16.04,2.24,Male,No,Sat,Dinner,3
17.46,2.54,Male,No,Sun,Dinner,2
13.94,3.06,Male,No,Sun,Dinner,2
9.68,1.32,Male,No,Sun,Dinner,2
30.4,5.6,Male,No,Sun,Dinner,4
18.29,3.0,Male,No,Sun,Dinner,2
22.23,5.0,Male,No,Sun,Dinner,2
32.4,6.0,Male,No,Sun,Dinner,4
28.55,2.05,Male,No,Sun,Dinner,3
18.04,3.0,Male,No,Sun,Dinner,2
12.54,2.5,Male,No,Sun,Dinner,2
10.29,2.6,Female,No,Sun,Dinner,2
34.81,5.2,Female,No,Sun,Dinner,4
9.94,1.56,Male,No,Sun,Dinner,2
25.56,4.34,Male,No,Sun,Dinner,4
19.49,3.51,Male,No,Sun,Dinner,2
38.01,3.0,Male,Yes,Sat,Dinner,4
26.41,1.5,Female,No,Sat,Dinner,2
11.24,1.76,Male,Yes,Sat,Dinner,2
48.27,6.73,Male,No,Sat,Dinner,4
20.29,3.21,Male,Yes,Sat,Dinner,2
13.81,2.0,Male,Yes,Sat,Dinner,2
11.02,1.98,Male,Yes,Sat,Dinner,2
18.29,3.76,Male,Yes,Sat,Dinner,4
17.59,2.64,Male,No,Sat,Dinner,3
20.08,3.15,Male,No,Sat,Dinner,3
16.45,2.47,Female,No,Sat,Dinner,2
3.07,1.0,Female,Yes,Sat,Dinner,1
20.23,2.01,Male,No,Sat,Dinner,2
15.01,2.09,Male,Yes,Sat,Dinner,2
12.02,1.97,Male,No,Sat,Dinner,2
17.07,3.0,Female,No,Sat,Dinner,3
26.86,3.14,Female,Yes,Sat,Dinner,2
25.28,5.0,Female,Yes,Sat,Dinner,2
14.73,2.2,Female,No,Sat,Dinner,2
10.51,1.25,Male,No,Sat,Dinner,2
17.92,3.08,Male,Yes,Sat,Dinner,2
27.2,4.0,Male,No,Thur,Lunch,4
22.76,3.0,Male,No,Thur,Lunch,2
17.29,2.71,Male,No,Thur,Lunch,2
19.44,3.0,Male,Yes,Thur,Lunch,2
16.66,3.4,Male,No,Thur,Lunch,2
10.07,1.83,Female,No,Thur,Lunch,1
32.68,5.0,Male,Yes,Thur,Lunch,2
15.98,2.03,Male,No,Thur,Lunch,2
34.83,5.17,Female,No,Thur,Lunch,4
13.03,2.0,Male,No,Thur,Lunch,2
18.28,4.0,Male,No,Thur,Lunch,2
24.71,5.85,Male,No,Thur,Lunch,2
21.16,3.0,Male,No,Thur,Lunch,2
28.97,3.0,Male,Yes,Fri,Dinner,2
22.49,3.5,Male,No,Fri,Dinner,2
5.75,1.0,Female,Yes,Fri,Dinner,2
16.32,4.3,Female,Yes,Fri,Dinner,2
22.75,3.25,Female,No,Fri,Dinner,2
40.17,4.73,Male,Yes,Fri,Dinner,4
27.28,4.0,Male,Yes,Fri,Dinner,2
12.03,1.5,Male,Yes,Fri,Dinner,2
21.01,3.0,Male,Yes,Fri,Dinner,2
12.46,1.5,Male,No,Fri,Dinner,2
11.35,2.5,Female,Yes,Fri,Dinner,2
15.38,3.0,Female,Yes,Fri,Dinner,2
44.3,2.5,Female,Yes,Sat,Dinner,3
22.42,3.48,Female,Yes,Sat,Dinner,2
20.92,4.08,Female,No,Sat,Dinner,2
15.36,1.64,Male,Yes,Sat,Dinner,2
20.49,4.06,Male,Yes,Sat,Dinner,2
25.21,4.29,Male,Yes,Sat,Dinner,2
18.24,3.76,Male,No,Sat,Dinner,2
14.31,4.0,Female,Yes,Sat,Dinner,2
14.0,3.0,Male,No,Sat,Dinner,2
7.25,1.0,Female,No,Sat,Dinner,1
38.07,4.0,Male,No,Sun,Dinner,3
23.95,2.55,Male,No,Sun,Dinner,2
25.71,4.0,Female,No,Sun,Dinner,3
17.31,3.5,Female,No,Sun,Dinner,2
29.93,5.07,Male,No,Sun,Dinner,4
10.65,1.5,Female,No,Thur,Lunch,2
12.43,1.8,Female,No,Thur,Lunch,2
24.08,2.92,Female,No,Thur,Lunch,4
11.69,2.31,Male,No,Thur,Lunch,2
13.42,1.68,Female,No,Thur,Lunch,2
14.26,2.5,Male,No,Thur,Lunch,2
15.95,2.0,Male,No,Thur,Lunch,2
12.48,2.52,Female,No,Thur,Lunch,2
29.8,4.2,Female,No,Thur,Lunch,6
8.52,1.48,Male,No,Thur,Lunch,2
14.52,2.0,Female,No,Thur,Lunch,2
11.38,2.0,Female,No,Thur,Lunch,2
22.82,2.18,Male,No,Thur,Lunch,3
19.08,1.5,Male,No,Thur,Lunch,2
20.27,2.83,Female,No,Thur,Lunch,2
11.17,1.5,Female,No,Thur,Lunch,2
12.26,2.0,Female,No,Thur,Lunch,2
18.26,3.25,Female,No,Thur,Lunch,2
8.51,1.25,Female,No,Thur,Lunch,2
10.33,2.0,Female,No,Thur,Lunch,2
14.15,2.0,Female,No,Thur,Lunch,2
16.0,2.0,Male,Yes,Thur,Lunch,2
13.16,2.75,Female,No,Thur,Lunch,2
17.47,3.5,Female,No,Thur,Lunch,2
34.3,6.7,Male,No,Thur,Lunch,6
41.19,5.0,Male,No,Thur,Lunch,5
27.05,5.0,Female,No,Thur,Lunch,6
16.43,2.3,Female,No,Thur,Lunch,2
8.35,1.5,Female,No,Thur,Lunch,2
18.64,1.36,Female,No,Thur,Lunch,3
11.87,1.63,Female,No,Thur,Lunch,2
9.78,1.73,Male,No,Thur,Lunch,2
7.51,2.0,Male,No,Thur,Lunch,2
14.07,2.5,Male,No,Sun,Dinner,2
13.13,2.0,Male,No,Sun,Dinner,2
17.26,2.74,Male,No,Sun,Dinner,3
24.55,2.0,Male,No,Sun,Dinner,4
19.77,2.0,Male,No,Sun,Dinner,4
29.85,5.14,Female,No,Sun,Dinner,5
48.17,5.0,Male,No,Sun,Dinner,6
25.0,3.75,Female,No,Sun,Dinner,4
13.39,2.61,Female,No,Sun,Dinner,2
16.49,2.0,Male,No,Sun,Dinner,4
21.5,3.5,Male,No,Sun,Dinner,4
12.66,2.5,Male,No,Sun,Dinner,2
16.21,2.0,Female,No,Sun,Dinner,3
13.81,2.0,Male,No,Sun,Dinner,2
17.51,3.0,Female,Yes,Sun,Dinner,2
24.52,3.48,Male,No,Sun,Dinner,3
20.76,2.24,Male,No,Sun,Dinner,2
31.71,4.5,Male,No,Sun,Dinner,4
10.59,1.61,Female,Yes,Sat,Dinner,2
10.63,2.0,Female,Yes,Sat,Dinner,2
50.81,10.0,Male,Yes,Sat,Dinner,3
15.81,3.16,Male,Yes,Sat,Dinner,2
7.25,5.15,Male,Yes,Sun,Dinner,2
31.85,3.18,Male,Yes,Sun,Dinner,2
16.82,4.0,Male,Yes,Sun,Dinner,2
32.9,3.11,Male,Yes,Sun,Dinner,2
17.89,2.0,Male,Yes,Sun,Dinner,2
14.48,2.0,Male,Yes,Sun,Dinner,2
9.6,4.0,Female,Yes,Sun,Dinner,2
34.63,3.55,Male,Yes,Sun,Dinner,2
34.65,3.68,Male,Yes,Sun,Dinner,4
23.33,5.65,Male,Yes,Sun,Dinner,2
45.35,3.5,Male,Yes,Sun,Dinner,3
23.17,6.5,Male,Yes,Sun,Dinner,4
40.55,3.0,Male,Yes,Sun,Dinner,2
20.69,5.0,Male,No,Sun,Dinner,5
20.9,3.5,Female,Yes,Sun,Dinner,3
30.46,2.0,Male,Yes,Sun,Dinner,5
18.15,3.5,Female,Yes,Sun,Dinner,3
23.1,4.0,Male,Yes,Sun,Dinner,3
15.69,1.5,Male,Yes,Sun,Dinner,2
19.81,4.19,Female,Yes,Thur,Lunch,2
28.44,2.56,Male,Yes,Thur,Lunch,2
15.48,2.02,Male,Yes,Thur,Lunch,2
16.58,4.0,Male,Yes,Thur,Lunch,2
7.56,1.44,Male,No,Thur,Lunch,2
10.34,2.0,Male,Yes,Thur,Lunch,2
43.11,5.0,Female,Yes,Thur,Lunch,4
13.0,2.0,Female,Yes,Thur,Lunch,2
13.51,2.0,Male,Yes,Thur,Lunch,2
18.71,4.0,Male,Yes,Thur,Lunch,3
12.74,2.01,Female,Yes,Thur,Lunch,2
13.0,2.0,Female,Yes,Thur,Lunch,2
16.4,2.5,Female,Yes,Thur,Lunch,2
20.53,4.0,Male,Yes,Thur,Lunch,4
16.47,3.23,Female,Yes,Thur,Lunch,3
26.59,3.41,Male,Yes,Sat,Dinner,3
38.73,3.0,Male,Yes,Sat,Dinner,4
24.27,2.03,Male,Yes,Sat,Dinner,2
12.76,2.23,Female,Yes,Sat,Dinner,2
30.06,2.0,Male,Yes,Sat,Dinner,3
25.89,5.16,Male,Yes,Sat,Dinner,4
48.33,9.0,Male,No,Sat,Dinner,4
13.27,2.5,Female,Yes,Sat,Dinner,2
28.17,6.5,Female,Yes,Sat,Dinner,3
12.9,1.1,Female,Yes,Sat,Dinner,2
28.15,3.0,Male,Yes,Sat,Dinner,5
11.59,1.5,Male,Yes,Sat,Dinner,2
7.74,1.44,Male,Yes,Sat,Dinner,2
30.14,3.09,Female,Yes,Sat,Dinner,4
12.16,2.2,Male,Yes,Fri,Lunch,2
13.42,3.48,Female,Yes,Fri,Lunch,2
8.58,1.92,Male,Yes,Fri,Lunch,1
15.98,3.0,Female,No,Fri,Lunch,3
13.42,1.58,Male,Yes,Fri,Lunch,2
16.27,2.5,Female,Yes,Fri,Lunch,2
10.09,2.0,Female,Yes,Fri,Lunch,2
20.45,3.0,Male,No,Sat,Dinner,4
13.28,2.72,Male,No,Sat,Dinner,2
22.12,2.88,Female,Yes,Sat,Dinner,2
24.01,2.0,Male,Yes,Sat,Dinner,4
15.69,3.0,Male,Yes,Sat,Dinner,3
11.61,3.39,Male,No,Sat,Dinner,2
10.77,1.47,Male,No,Sat,Dinner,2
15.53,3.0,Male,Yes,Sat,Dinner,2
10.07,1.25,Male,No,Sat,Dinner,2
12.6,1.0,Male,Yes,Sat,Dinner,2
32.83,1.17,Male,Yes,Sat,Dinner,2
35.83,4.67,Female,No,Sat,Dinner,3
29.03,5.92,Male,No,Sat,Dinner,3
27.18,2.0,Female,Yes,Sat,Dinner,2
22.67,2.0,Male,Yes,Sat,Dinner,2
17.82,1.75,Male,No,Sat,Dinner,2
18.78,3.0,Female,No,Thur,Dinner,2
'''

import pandas as pd
import io

# Use this if you want to download data from Google drive
# !wget https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/276/original/tips.csv?1645193273 -O tips.csv
# df = pd.read_csv('tips.csv')
df = pd.read_csv(io.StringIO(q3_csv_data))
print(df)

print(f"""
pd.DataFrame(df, columns=['time', 'total_bill', 'tip']) =
{pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])}
""", end = "\n")

print(f"""
df[['time', 'total_bill', 'tip']] ="
{df[['time', 'total_bill', 'tip']]}
""", end = "\n")

print(f"""
df.loc[:, ['time', 'total_bill', 'tip']] =
{df.loc[:, ['time', 'total_bill', 'tip']]}
""", end = "\n")

print(f"""
df.iloc[:,0:2] =
{df.iloc[:,0:2]}
""", end = "\n")

"""# **Q4. loc and iloc**

Given, a dataframe df:

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Gender</th>
      <th>Profession</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Jim</td>
      <td>M</td>
      <td>Athlete</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Carry</td>
      <td>F</td>
      <td>Tech</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Chris</td>
      <td>M</td>
      <td>Cricketer</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Morris</td>
      <td>M</td>
      <td>Actor</td>
    </tr>
  </tbody>
</table>

The following codes are executed on the data frame df

```python
df.iloc[:2,:2]
#line a
df.loc[:2,"Name":"Profession"]
#line b
```

From the above-given information, mark the option which is true regarding the following statements.

1. For line a, the output is the first two rows with the three columns ["Name", "Gender", "Profession"].

2. For line a, the output is the first two rows with the two columns ["Name", "Gender"].

3. For line b, the output is the row with labels 0, 1, and 2 with the columns ["Name", "Gender", "Profession"].

4. For line b, TypeError will be generated.

#### **Ans:**

Options 2 & 3:

* For line a, the output is the first two rows with the two columns ["Name", "Gender"].
* For line b, the output is the row with labels 0, 1, and 2 with the columns ["Name", "Gender", "Profession"].
"""

import pandas as pd
import numpy as np

data = {
    'Name':['Jim', 'Carry', 'Chris', 'Morris'],
    'Gender': ['M', 'F', 'M', 'M'],
    'Profession': ['Athlete', 'Tech', 'Cricketer', 'Actor']
}

df = pd.DataFrame(data)
df.iloc[:2,:2]
#line a
df.loc[:2,"Name":"Profession"]
#line b

"""# **Q5. Select the required data**

Given the dataset of 10 car models and their respective features, what would be the correct code to get following result:

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>disp</th>
      <th>hp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Mazda RX4 Wag</td>
      <td>160.0</td>
      <td>110</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Datsun 710</td>
      <td>108.0</td>
      <td>93</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Hornet 4 Drive</td>
      <td>258.0</td>
      <td>110</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Hornet Sportabout</td>
      <td>360.0</td>
      <td>175</td>
    </tr>
  </tbody>
</table>
"""

# Use this if you want to download data from Google drive
# !gdown 1UcWItyfVGL-mPlnR002bDRx_rdkSbgGq
# df = pd.read_csv('mtcars.csv')

q5_csv_data = f'''
model,mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb
Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4
Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4
Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1
Hornet 4 Drive,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1
Hornet Sportabout,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2
Valiant,18.1,6,225,105,2.76,3.46,20.22,1,0,3,1
Duster 360,14.3,8,360,245,3.21,3.57,15.84,0,0,3,4
Merc 240D,24.4,4,146.7,62,3.69,3.19,20,1,0,4,2
Merc 230,22.8,4,140.8,95,3.92,3.15,22.9,1,0,4,2
Merc 280,19.2,6,167.6,123,3.92,3.44,18.3,1,0,4,4
Merc 280C,17.8,6,167.6,123,3.92,3.44,18.9,1,0,4,4
Merc 450SE,16.4,8,275.8,180,3.07,4.07,17.4,0,0,3,3
Merc 450SL,17.3,8,275.8,180,3.07,3.73,17.6,0,0,3,3
Merc 450SLC,15.2,8,275.8,180,3.07,3.78,18,0,0,3,3
Cadillac Fleetwood,10.4,8,472,205,2.93,5.25,17.98,0,0,3,4
Lincoln Continental,10.4,8,460,215,3,5.424,17.82,0,0,3,4
Chrysler Imperial,14.7,8,440,230,3.23,5.345,17.42,0,0,3,4
Fiat 128,32.4,4,78.7,66,4.08,2.2,19.47,1,1,4,1
Honda Civic,30.4,4,75.7,52,4.93,1.615,18.52,1,1,4,2
Toyota Corolla,33.9,4,71.1,65,4.22,1.835,19.9,1,1,4,1
Toyota Corona,21.5,4,120.1,97,3.7,2.465,20.01,1,0,3,1
Dodge Challenger,15.5,8,318,150,2.76,3.52,16.87,0,0,3,2
AMC Javelin,15.2,8,304,150,3.15,3.435,17.3,0,0,3,2
Camaro Z28,13.3,8,350,245,3.73,3.84,15.41,0,0,3,4
Pontiac Firebird,19.2,8,400,175,3.08,3.845,17.05,0,0,3,2
Fiat X1-9,27.3,4,79,66,4.08,1.935,18.9,1,1,4,1
Porsche 914-2,26,4,120.3,91,4.43,2.14,16.7,0,1,5,2
Lotus Europa,30.4,4,95.1,113,3.77,1.513,16.9,1,1,5,2
Ford Pantera L,15.8,8,351,264,4.22,3.17,14.5,0,1,5,4
Ferrari Dino,19.7,6,145,175,3.62,2.77,15.5,0,1,5,6
Maserati Bora,15,8,301,335,3.54,3.57,14.6,0,1,5,8
Volvo 142E,21.4,4,121,109,4.11,2.78,18.6,1,1,4,2
'''

import pandas as pd
import numpy as np
import io

# Use this if you want to download data from Google drive
# !gdown 1UcWItyfVGL-mPlnR002bDRx_rdkSbgGq
# data = pd.read_csv('mtcars.csv')

data = pd.read_csv(io.StringIO(q5_csv_data))
data.iloc[1:5, [0, 3, 4]].to_html()

"""# **AQ1. The selected rows**

**Problem Description:**

Given a dataframe containing transaction data sorted in order of transaction date, and row range r1 (start index) and r2 (end index).

* Filter out the rows between r1 and r2 (r2 is exclusive).
* Complete the function select_rows() to do the same, with dataframe and r1 and r2 values provided to the function.
* Return only the "name" and "amt" columns from the filtered dataframe.

**Sample Input:**

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>name</th>
      <th>amt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020-01-10</td>
      <td>Himanshu</td>
      <td>100</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020-07-01</td>
      <td>Robert</td>
      <td>200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020-08-01</td>
      <td>Karie</td>
      <td>400</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2020-03-02</td>
      <td>Rohan</td>
      <td>150</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020-01-03</td>
      <td>John</td>
      <td>300</td>
    </tr>
  </tbody>
</table>

**Sample Output:**
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>amt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Robert</td>
      <td>200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Karie</td>
      <td>400</td>
    </tr>
  </tbody>
</table>
"""

aq1_csv_data = f'''
date,name,amt
2020-01-10,Himanshu,100
2020-07-01,Robert,200
2020-08-01,Karie,400
2020-03-02,Rohan,150
2020-01-03,John,300
'''

import pandas as pd
import io

def select_rows(df, r1, r2):
    '''
    input:
    df -> the dataframe provided to the function
    r1 -> the starting index of the rows to be selected
    r2 -> the ending index of the rows to be selected

    output:
    df_new -> the selected rows of the dataframe
    '''

    # Select the rows r1 to r2
    df_selected = df.iloc[r1:r2]

    # Select the columns "name" and "amt"
    df_new = df_selected[["name", "amt"]]

    return df_new

df = pd.read_csv(io.StringIO(aq1_csv_data))
df_new = select_rows(df, 1, 3)
print(df_new)

"""# **Q2. Display all the rows**

Given the dataset in Q5 of car models and their respective features, What would be the correct code to print every row of the "disp" column?

**Options:**

1. data.loc[:,'disp']
2. data['disp']
3. data.iloc[:,'disp']
4. data.loc['disp',:]
"""

import pandas as pd
import io

data = pd.read_csv(io.StringIO(q5_csv_data))
print(f"""
data.loc[:,'disp'] =
{data.loc[:,'disp']}
""")

print(f"""
data['disp'] =
{data['disp']}
""")

"""# **AQ3. Satisfied customers**

Given a dataframe

Return a subset of the dataframe with records having **rating >= 6**, containing the columns **"profession"**, **"gender"** and **"age"** only.

**Sample Input:**
```json
{'name':["Sam","Roma","Mark"], "profession":['dev','mle','Data scientist'],"gender":['male','female','male'], "age":[21,20,25],"review":['No comments','hardworker','need improvement'],"rating":[10,5,7]}
```

**Sample Output:**

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>profession</th>
      <th>gender</th>
      <th>age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>dev</td>
      <td>male</td>
      <td>21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Data scientist</td>
      <td>male</td>
      <td>25</td>
    </tr>
  </tbody>
</table>

"""

import pandas as pd
def filtered_customers(df):
    ''' df is a dataframe with columns ['name', 'profession', 'gender', 'age', 'review', 'rating']
        Output -> A dataframe with required rows is expected to be returned'''

    # YOUR CODE GOES HERE
    # Filter the dataframe having ratings>=6 and choose the required columns
    new_df = df[df['rating'] >= 6][['profession', 'gender', 'age']]

    return new_df

data = {
    'name': ["Sam","Roma","Mark"],
    'profession': ['dev','mle','Data scientist'],
    'gender': ['male','female','male'],
    'age': [21,20,25],
    'review': ['No comments','hardworker','need improvement'],
    'rating':[ 10,5,7]
}

df = pd.DataFrame(data)
print(filtered_customers(df))

"""# **AQ4. Correct way to form a dataframe?**

Which of these would be the correct way to create a dataframe?

a.

```python
df = pd.DataFrame([[1, 2], ["Ram", "Shyam"], ["IT", "Ops"]], columns = ["emp_id", "name", "dept"])
```

b.

```python
df = pd.DataFrame([[1, "Ram", "IT"], [2, "Shyam", "Ops"]], columns = ["emp_id", "name", "dept"])
```

c.

```
df = pd.DataFrame([1, "Ram", "IT"], columns = ["emp_id", "name", "dept"])
```

d.

```
df = pd.DataFrame({'emp_id':[1, 2], 'name': ['Ram', 'Shyam'], 'dept':['IT', 'Ops']})
```

#### **Ans:**

Option b & d
"""