# -*- coding: utf-8 -*-
"""Pandas-3 notes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cKNDeCTJgkyWfFbrb8bnentxSHdMNf0c

# Pandas 3

---

## Content

- Introduction to IMDB use case
    - Merging `movies` & `directors` datasets
    - IMDB data exploration (Post-read)
- `apply()`
- `groupby()`
    - Group based Aggregation
    - Group based Filtering
    - Group based Apply

---

## **IMDB Movies Data**

- Imagine you are working as a Data Scientist for an analytics firm.
- Your task is to analyse some **movie trends** for a client.
- **IMDB** has an online database of information related to movies.

Let's download and read the IMDB dataset -

- File1: https://drive.google.com/file/d/1s2TkjSpzNc4SyxqRrQleZyDIHlc7bxnd/view?usp=sharing
- File2: https://drive.google.com/file/d/1Ws-_s1fHZ9nHfGLVUQurbHDvStePlEJm/view?usp=sharing
"""

!pip install --upgrade gdown

!gdown 1s2TkjSpzNc4SyxqRrQleZyDIHlc7bxnd

!gdown 1Ws-_s1fHZ9nHfGLVUQurbHDvStePlEJm

"""Here we have two CSV files -
- `movies.csv`
- `directors.csv`
"""

import pandas as pd
import numpy as np

movies = pd.read_csv('movies.csv')
movies.head()

"""**So what kind of questions can we ask from this dataset?**

- **Top 10 most popular movies**, using `popularity`.
- Find the **highest rated movies**, using `vote_average`.
- We can find number of **movies released per year**.
- Find **highest budget movies in a year** using both `budget` and `year`.

**But can we ask more interesting/deeper questions?**

- Do you think we can find the **most productive directors**?
- Which **directors produce high budget films**?
- **Highest and lowest rated movies for every month** in a particular year?

Notice that there's a column **Unnamed: 0** which represents nothing but the index of a row.

**How to get rid of this `Unnamed: 0` col?**
"""

movies = pd.read_csv('movies.csv', index_col=0)
movies.head()

"""`index_col=0` explicitly states to treat the first column as the index.

The default value is `index_col=None`
"""

movies.shape

"""The `movies` dataframe contains 1465 rows and 11 columns."""

directors = pd.read_csv('directors.csv', index_col=0)
directors.head()

directors.shape

"""The `directors` dataframe contains 2349 rows and 3 columns.

---

### Merging `movies` & `directors` datasets

**How can we know the details about the Director of a particular movie?**

- We will have to merge these two datasets.

**So on which column we should merge?**

We will use the **ID** columns (representing unique directors) in both the datasets.

If you observe,

- `director_id` of movies are taken from `id` of directors.
- Thus, we can merge our dataframes based on these two columns as **keys**.

Before that, let's first check the number of unique directors in our `movies` dataset.

**How do we get the number of unique directors in `movies`?**
"""

movies['director_id'].nunique()

"""Recall, we had learnt about `nunique()` earlier."""

directors['id'].nunique()

"""**Summary:**

- `movies` dataset: 1465 rows, but only 199 unique directors
- `directors` dataset: 2349 unique directors (equal to the no. of rows)

**What can we infer from this?**

- The directors in `movies` data is a subset of directors in `directors` data.

**How can we check if all `director_id` values are present in `id`?**
"""

movies['director_id'].isin(directors['id'])

"""The `isin()` method checks if a column contains the specified value(s).

**How is `isin` different from Python's `in`?**

- `in` works for **one element** at a time.
- `isin` does this for **all the values** in the column.

If you notice,

- This is like a **boolean mask**.
- It returns a dataframe similar to the original one.
- For rows with values of `director_id` present in `id`, it returns True, else False.

**How can we check if there's any False here?**
"""

np.all(movies['director_id'].isin(directors['id']))

"""Let's finally merge the two dataframes.

Do we need to keep **all the rows for movies**? Yes!

Do we need to keep **all the rows of directors**? No.

- Only the ones for which we have a corresponding row in `movies`.

**So which `join` type do you think we should apply here?**

- `LEFT` Join
"""

data = movies.merge(directors, how='left', left_on='director_id',right_on='id')
data

"""Notice the two strange id columns - `id_x` and `id_y`.

**What do you think these newly created columns are?**

Since the columns with name `id` are present in both the dataframes,
- `id_x` represents **id values from movie df**
- `id_y` represents **id values from directors df**

**Do you think any column is redundant here and can be dropped?**

- `id_y` is redundant as it is the same as `director_id`
- But we don't require the `director_id` any further.

So we can simply drop these features -
"""

data.drop(['director_id','id_y'], axis=1, inplace=True)
data.head()

"""---

### Post-read

- [IMDB data exploration](https://colab.research.google.com/drive/1yrfHSQYUMxxLKGUG-gCPf-R232BuimiR?usp=sharing)

From here, we have the opportunity to delve into various aspects of the data, such as:

- Converting the revenue values into Millions of USD.
- Identifying the Top 5 most popular movies.

... and so on.

This task is for you to explore the data on your own.

Additionally, we've provided a notebook (accessible as **post-lecture content**) where this analysis has been conducted.

---

### `apply()`

- It is used apply a function along an axis of the DataFrame/Series.

Say we want to convert the data in `Gender` column into numerical format.

Basically,
- 0 for Male
- 1 for Female

**How can we encode the values in the `Gender` column?**

Let's first write a function to do it for a single value.
"""

def encode(data):
  if data == "Male":
    return 0
  else:
    return 1

"""**Now how can we apply this function to the whole column?**"""

data['gender'] = data['gender'].apply(encode)
data

"""Notice how this is similar to using `Vectorization` in Numpy.

**How to apply a function on multiple columns?**

Let's say we want to find the sum of `revenue` and `budget` per movie?
"""

data[['revenue', 'budget']].apply(np.sum)

"""We can pass multiple columns by packing them within `[]`.

But there's a mistake here. We wanted our results per movie (i.e. per row)

But we're getting the sum of the columns.
"""

data[['revenue', 'budget']].apply(np.sum, axis=1)

"""By setting the `axis=1`, every row of `revenue` was added to same row of `budget`.

**What does this `axis` mean in apply?**
- `axis=0` $\rightarrow$ It will apply to **each column**
- `axis=1` $\rightarrow$ It will apply to **each row**
  
Note that **by default, axis=0**.

**Similarly, how can I find the `profit` per movie (revenue-budget)?**
"""

# We define a function to calculate profit

def prof(x):
  return x['revenue']-x['budget']
data['profit'] = data[['revenue', 'budget']].apply(prof, axis = 1)
data

"""---

### What is Grouping?

In simple terms, we could understood it through - Split, Apply, Combine

<img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781491912126/files/assets/pyds_03in01.png" height="350" width="700"/>

1. **Split**: Breaking up and grouping a DataFrame depending on the value of the specified key.

2. **Apply**: Computing some function, usually an aggregate, transformation, or filtering, within the individual groups.

3. **Combine**: Merging the results of these operations into an output array.

---

### Group based Aggregation

We use different aggregate functions like `mean`, `sum`, `min`, `max`, `count` etc. on columns while grouping.

Let's group our data director-wise.
"""

data.groupby('director_name')

"""Notice,
- It's a **DataFrameGroupBy** type object
- **NOT a DataFrame** type object

**What's the number of groups our data is divided into?**
"""

data.groupby('director_name').ngroups

"""Based on this grouping, we can find which keys belong to which group."""

data.groupby('director_name').groups

"""**What if we want to extract data of a particular group from this list?**"""

data.groupby('director_name').get_group('Alexander Payne')

"""**How can we find the count of movies by each director?**"""

data.groupby('director_name')['title'].count()

"""**How to find multiple aggregates of any feature?**

Finding the very first year and the latest year a director released a movie i.e basically the **min** & **max** of the `year` column, grouped by `director_name`.
"""

data.groupby(['director_name'])["year"].aggregate(['min', 'max'])

"""**Note:** We can also use `.agg` instead of `.aggregate` (both are same)

---

### Group based Filtering

Group based filtering allows us to filter rows from each group by using conditional statements on each group rather than the whole dataframe.

**How to find the details of the movies by high budget directors?**

- Lets assume, high budget director -> any director with **atleast one movie with budget >100M**.

1. We can **group** the data by director and use `max` of the budget as aggregator.
"""

data_dir_budget = data.groupby("director_name")["budget"].max().reset_index()
data_dir_budget.head()

"""2. We can **filter** out the director names with **max budget >100M**."""

names = data_dir_budget.loc[data_dir_budget["budget"] >= 100, "director_name"]

"""3. Finally, we can filter out the details of the movies by these directors."""

data.loc[data['director_name'].isin(names)]

"""**Can we filter groups in a single go using Lambda functions?** Yes!"""

data.groupby('director_name').filter(lambda x: x["budget"].max() >= 100)

"""Notice what's happening here?

- We first group data by director and then use `groupby().filter` function.
- **Groups are filtered if they do not satisfy the boolean criterion** specified by the function.
- This is called **Group Based Filtering**.

**Note:**
- We are filtering the **groups** here and **not the rows**.
- The result is **not a groupby object** but regular **Pandas DataFrame** with the **filtered groups eliminated**.

---

### Group based Apply

- applying a function on grouped objects

**What if we want to do the transformation of a column using some column's agrregate**

Let's say, we want to filter the risky movies whose budget was even higher than the average revenue of the director from his other movies.

We can subtract the average `revenue` of a director from `budget` column, for each director.
"""

def func(x):
  # returns whether a movie is risky or not
  x["risky"] = x["budget"] - x["revenue"].mean() >= 0
  return x

data_risky = data.groupby("director_name", group_keys=False).apply(func)
data_risky

"""**Note:**
- Setting `group_keys=True`, keeps the group key in the returned dataset.
- This will be default in future versions of Pandas.
- Keep it as False if want the normal behaviour.

**What did we do here?**

- Defined a custom function.
- Grouped data according to `director_name`.
- Subtracted the mean of `budget` from `revenue`.
- Used apply with the custom function on the grouped data.

Now let's see if there are any risky movies -
"""

data_risky.loc[data_risky["risky"]]

"""---"""