# -*- coding: utf-8 -*-
"""Pandas-4 notes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hRTaHy3POrA-BkcN43fasbdm2RyZNQIA

# Pandas 4

---

## Content

- Multi-indexing
- Melting
  - `pd.melt()`
- Pivoting
  - `pd.pivot()`
  - `pd.pivot_table()`
- Binning
  - `pd.cut()`

---

### Multi-Indexing
"""

!pip install --upgrade gdown

!gdown 1s2TkjSpzNc4SyxqRrQleZyDIHlc7bxnd
!gdown 1Ws-_s1fHZ9nHfGLVUQurbHDvStePlEJm

import pandas as pd
import numpy as np

movies = pd.read_csv('movies.csv', index_col=0)
directors = pd.read_csv('directors.csv', index_col=0)

data = movies.merge(directors, how='left', left_on='director_id',right_on='id')
data.drop(['director_id','id_y'],axis=1,inplace=True)

"""**Which director according to you should be considered as most productive?**

- Should we decide based on the **number of movies** directed?
- Or take the **quality of the movies** into consideration as well?
- Or maybe look at the the **amount of business** the movie is doing?

To simplify, let's calculate who has directed maximum number of movies.
"""

data.groupby(['director_name'])['title'].count().sort_values(ascending=False)

"""`Steven Spielberg` has directed maximum number of movies.

**But does it make `Steven` the most productive director?**

- Chances are, he might be active for more years than the other directors.

**Calculating the active years for every director?**

- We can subtract both `min` and `max` of year.
"""

data_agg = data.groupby(['director_name'])[["year", "title"]].aggregate({"year":['min','max'], "title": "count"})
data_agg

"""Notice,
- `director_name` column has turned into **row labels**.
- There are multiple levels for the column names.

This is called a **Multi-index DataFrame**.

- It can have **multiple indexes along a dimension**.
  - The no. of dimensions remain same though.
- Multi-level indexes are **possible both for rows and columns**.
"""

data_agg.columns

"""The level-1 column names are `year` and `title`.

**What would happen if we print the column `year` of this multi-index dataframe?**
"""

data_agg["year"]

"""**How can we convert multi-level back to only one level of columns?**

- e.g. `year_min`, `year_max`, `title_count`
"""

data_agg = data.groupby(['director_name'])[["year","title"]].aggregate(
    {"year":['min', 'max'], "title": "count"})

data_agg.columns = ['_'.join(col) for col in data_agg.columns]
data_agg

"""Since these were tuples, we can just join them."""

data.groupby('director_name')[['year', 'title']].aggregate(
    year_max=('year','max'),
    year_min=('year','min'),
    title_count=('title','count')
)

"""The columns look good, but we may want to turn back the row labels into a proper column as well.

**Converting row labels into a column using `reset_index` -**
"""

data_agg.reset_index()

"""**Using the new features, can we find the most productive director?**

1. First calculate how many years the director has been active.
"""

data_agg["yrs_active"] = data_agg["year_max"] - data_agg["year_min"]
data_agg

"""2. Then calculate rate of directing movies by `title_count`/`yrs_active`."""

data_agg["movie_per_yr"] = data_agg["title_count"] / data_agg["yrs_active"]
data_agg

"""3. Finally, sort the values."""

data_agg.sort_values("movie_per_yr", ascending=False)

"""**Conclusion:**

- `Tyler Perry` turns out to be truly the most productive director.

---

### PFizer data

For this topic we will be using data of few drugs being developed by **PFizer**.

Dataset: https://drive.google.com/file/d/173A59xh2mnpmljCCB9bhC4C5eP2IS6qZ/view?usp=sharing
"""

!gdown 173A59xh2mnpmljCCB9bhC4C5eP2IS6qZ

"""**What is the data about?**
- Temperature (K)
- Pressure (P)

The data is recorded after an **interval of 1 hour** everyday to monitor the drug stability in a drug development test.

These data points are therefore used to **identify the optimal set of values of parameters** for the stability of the drugs.

Let's explore this dataset -
"""

data = pd.read_csv('Pfizer_1.csv')
data

data.info()

"""---

## Melting

As we saw earlier, the dataset has **18 rows** and **15 columns**.

If you notice further, you'll see:
- The columns are `1:30:00`, `2:30:00`, `3:30:00`, ... so on.
- `Temperature` and `Pressure` of each date is in a separate row.

**Can we restructure our data into a better format?**

- Maybe we can have a column for `time`, with `timestamps` as the column value.

**Where will the Temperature/Pressure values go?**

- We can similarly create one column containing the values of these parameters.
- "Melt" the timestamp column into two columns** - timestamp and corresponding values

**How can we restructure our data into having every row corresponding to a single reading?**
"""

pd.melt(data, id_vars=['Date', 'Parameter', 'Drug_Name'])

"""This converts our data from `wide` to `long` format.

Notice that the `id_vars` are set of variables which remain unmelted.

**How does `pd.melt()` work?**

- Pass in the **DataFrame**.
- Pass in the **column names that we don't want to melt**.

But we can provide better names to these new columns.

**How can we rename the columns "variable" and "value" as per our original dataframe?**
"""

data_melt = pd.melt(data,id_vars = ['Date', 'Drug_Name', 'Parameter'],
            var_name = "time",
            value_name = 'reading')
data_melt

"""**Conclusion:**

- The labels of the timestamp columns are conviniently **melted into a single column** - `time`
- It retained all the values in `reading` column.
- The labels of columns such as `1:30:00`, `2:30:00` have now become categories of the `variable` column.
- The values from columns we are melting are stored in the `value` column.

---

### Pivoting

Now suppose we want to convert our data back to the **wide format**.

The reason could be to maintain the structure for storing or some other purpose.

Notice,

- The variables `Date`, `Drug_Name` and `Parameter` will remain same.
- The column names will be extracted from the column `time`.
- The values will be extracted from the column `readings`.

**How can we restructure our data back to the original wide format?**
"""

data_melt.pivot(index=['Date','Drug_Name','Parameter'],  # Columns used to make new frame’s index
                columns = 'time',                        # Column used to make new frame’s columns
                values='reading')                        # Column used for populating new frame’s values.

"""Notice that `pivot()` is the exact opposite of `melt()`.

We are getting **multiple indices** here, but we can get single index again using `reset_index()`.
"""

data_melt.pivot(index=['Date','Drug_Name','Parameter'],
                columns = 'time',
                values='reading').reset_index()

data_melt.head()

"""Now if you notice,
- We are using 2 rows to log readings for a single experiment.

**Can we further restructure our data into dividing the `Parameter` column into T/P?**

- A format like `Date | time | Drug_Name | Pressure | Temperature` would be suitable.
- We want to **split one single column into multiple columns**.

**How can we divide the `Parameter` column again?**
"""

data_tidy = data_melt.pivot(index=['Date','time', 'Drug_Name'],
                            columns = 'Parameter',
                            values='reading')
data_tidy

"""Notice that a **multi-index** dataframe has been created.

We can use `reset_index()` to remove the multi-index.
"""

data_tidy = data_tidy.reset_index()
data_tidy

"""We can rename our ```index``` column from `Parameter` to simply `None`."""

data_tidy.columns.name = None
data_tidy.head()

"""---

### Pivot Table

Now suppose we want to find some insights, like **mean temperature day-wise**.

**Can we use pivot to find the day-wise mean value of temperature for each drug?**
"""

data_tidy.pivot(index=['Drug_Name'],
                columns = 'Date',
                values=['Temperature'])

"""**Why did we get an error?**

- We need to find the **average** of temperature values throughout a day.
- If you notice, the error shows **duplicate entries**.

Hence, the index values should be unique entry for each row.

**What can we do to get our required mean values then?**

"""

pd.pivot_table(data_tidy, index='Drug_Name', columns='Date', values=['Temperature'], aggfunc=np.mean)

"""This function is similar to `pivot()`, with an extra feature of an aggregator.

**How does `pivot_table()` work?**

- The initial parameters are same as what we use in `pivot()`.
- As an extra parameter, we pass the **type of aggregator**.

**Note:**

- We could have done this using `groupby` too.
- In fact, `pivot_table` uses `groupby` in the backend to group the data and perform the aggregration.
- The only difference is in the type of output we get using both the functions.

**Similarly, what if we want to find the minimum values of temperature and pressure on a particular date?**
"""

pd.pivot_table(data_tidy, index='Drug_Name', columns='Date', values=['Temperature', 'Pressure'], aggfunc=np.min)

"""---

### Binning

Sometimes, we would want our data to be in **categorical** form instead of **continuous/numerical**.

- Let's say, instead of knowing specific test values of a month, I want to know its type.
- Depending on the level of granularity, we want to have - Low, Medium, High, Very High.

**How can we derive bins/buckets from continous data?**

- use `pd.cut()`

Let's try to use this on our `Temperature` column to categorise the data into bins.

But to define categories, let's first check `min` and `max` temperature values.
"""

data_tidy

print(data_tidy['Temperature'].min(), data_tidy['Temperature'].max())

"""Here,
- Min value = 8
- Max value = 58

Lets's keep some buffer for future values and take the range from 5-60 (instead of 8-58).

We'll divide this data into **4 bins** of 10-15 values each.
"""

temp_points = [5, 20, 35, 50, 60]

temp_labels = ['low','medium','high','very_high'] # labels define the severity of the resultant output of the test

data_tidy['temp_cat'] = pd.cut(data_tidy['Temperature'], bins=temp_points, labels=temp_labels)
data_tidy.head()

data_tidy['temp_cat'].value_counts()

"""**Note:** By default, `pd.cut()` creates intervals of the form (x, y] — which includes the right endpoint but excludes the left one.

---
"""