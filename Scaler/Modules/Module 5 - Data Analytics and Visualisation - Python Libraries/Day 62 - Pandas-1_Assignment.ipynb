{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "$\\newcommand{\\trinom}[3]{\\begin{pmatrix} #1 \\\\ #2 \\\\ #3 \\end{pmatrix}}$"
      ],
      "metadata": {
        "id": "7kTvDjuadqn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1. First 20**\n",
        "\n",
        "Which of the following options will return the first 20 rows of a given dataframe **df**?\n",
        "\n",
        "1. df.head()\n",
        "2. df.head(20)\n",
        "3. df.tail(20)\n",
        "4. df.iloc[:20]"
      ],
      "metadata": {
        "id": "ANuD_mYtti85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Options 2 & 4:\n",
        "* df.head(20)\n",
        "* df.iloc[:20]\n",
        "\n",
        "**Explanation:** See code below"
      ],
      "metadata": {
        "id": "wOLpmDn8O932"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(np.arange(300).reshape(30, 10))\n",
        "print(df.head(20))\n",
        "print(df.iloc[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwKjP7kCBTxF",
        "outputId": "2fba7bd0-5c7b-41e1-98a2-5c08edee37e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0    1    2    3    4    5    6    7    8    9\n",
            "0     0    1    2    3    4    5    6    7    8    9\n",
            "1    10   11   12   13   14   15   16   17   18   19\n",
            "2    20   21   22   23   24   25   26   27   28   29\n",
            "3    30   31   32   33   34   35   36   37   38   39\n",
            "4    40   41   42   43   44   45   46   47   48   49\n",
            "5    50   51   52   53   54   55   56   57   58   59\n",
            "6    60   61   62   63   64   65   66   67   68   69\n",
            "7    70   71   72   73   74   75   76   77   78   79\n",
            "8    80   81   82   83   84   85   86   87   88   89\n",
            "9    90   91   92   93   94   95   96   97   98   99\n",
            "10  100  101  102  103  104  105  106  107  108  109\n",
            "11  110  111  112  113  114  115  116  117  118  119\n",
            "12  120  121  122  123  124  125  126  127  128  129\n",
            "13  130  131  132  133  134  135  136  137  138  139\n",
            "14  140  141  142  143  144  145  146  147  148  149\n",
            "15  150  151  152  153  154  155  156  157  158  159\n",
            "16  160  161  162  163  164  165  166  167  168  169\n",
            "17  170  171  172  173  174  175  176  177  178  179\n",
            "18  180  181  182  183  184  185  186  187  188  189\n",
            "19  190  191  192  193  194  195  196  197  198  199\n",
            "      0    1    2    3    4    5    6    7    8    9\n",
            "0     0    1    2    3    4    5    6    7    8    9\n",
            "1    10   11   12   13   14   15   16   17   18   19\n",
            "2    20   21   22   23   24   25   26   27   28   29\n",
            "3    30   31   32   33   34   35   36   37   38   39\n",
            "4    40   41   42   43   44   45   46   47   48   49\n",
            "5    50   51   52   53   54   55   56   57   58   59\n",
            "6    60   61   62   63   64   65   66   67   68   69\n",
            "7    70   71   72   73   74   75   76   77   78   79\n",
            "8    80   81   82   83   84   85   86   87   88   89\n",
            "9    90   91   92   93   94   95   96   97   98   99\n",
            "10  100  101  102  103  104  105  106  107  108  109\n",
            "11  110  111  112  113  114  115  116  117  118  119\n",
            "12  120  121  122  123  124  125  126  127  128  129\n",
            "13  130  131  132  133  134  135  136  137  138  139\n",
            "14  140  141  142  143  144  145  146  147  148  149\n",
            "15  150  151  152  153  154  155  156  157  158  159\n",
            "16  160  161  162  163  164  165  166  167  168  169\n",
            "17  170  171  172  173  174  175  176  177  178  179\n",
            "18  180  181  182  183  184  185  186  187  188  189\n",
            "19  190  191  192  193  194  195  196  197  198  199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2. Be unique**\n",
        "\n",
        "Which of the following statements are true?\n",
        "\n",
        "1. .unique() method returns unique values in a Series.\n",
        "2. .unique(), when applied on a dataframe returns unique values for each column.\n",
        "3. .nunique() method returns the count of unique elements in a Series.\n",
        "4. .nunique(), when applied on a dataframe returns the number of unique elements for each column."
      ],
      "metadata": {
        "id": "zpPTjWZOud3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Options 1, 3 & 4\n",
        "\n",
        "* .unique() method returns unique values in a Series.\n",
        "* .nunique() method returns the count of unique elements in a Series.\n",
        "* .nunique(), when applied on a dataframe returns the number of unique elements for each column.\n",
        "\n",
        "**Explanation:** See code below"
      ],
      "metadata": {
        "id": "zAKo9QDuzbFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "df_num_cols = 10\n",
        "df_num_rows = 15\n",
        "dfcols = list(chr(ord('A') + i) for i in range(df_num_cols))\n",
        "df = pd.DataFrame(\n",
        "    np.random.randint(0,\n",
        "        df_num_rows * df_num_cols,\n",
        "        size=(df_num_rows, df_num_cols)),\n",
        "    columns=dfcols)\n",
        "print(f\"\"\"\n",
        "Data sample:\n",
        "{df}\n",
        "\"\"\")\n",
        "uniques = [\n",
        "    {\n",
        "      'col': col,\n",
        "      # 'unique_count': df[col].nunique(),\n",
        "      'unique_values': str(df[col].unique().tolist())\n",
        "    } for col in df.columns]\n",
        "\n",
        "print(f\"\"\"\n",
        "Uniques output:\n",
        "{json.dumps(uniques, indent = 2)}\n",
        "\n",
        "Total uniques in df:\n",
        "{df.nunique()}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhR6IWNFx1rJ",
        "outputId": "7c45b01c-a4b8-474a-863e-d18904db9c06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data sample:\n",
            "      A    B    C    D    E    F    G    H    I    J\n",
            "0   102  101   14   66   94   71   50  136   41   23\n",
            "1   106  127  120   82   80   16   47   74    5   60\n",
            "2    62  138   14  139   88  131   44   68   10  110\n",
            "3   101  120    3  146   49   15  109   20   61   79\n",
            "4    23  125  104  119  144   22    4  144   70   87\n",
            "5    67   46  143   19   10  136  136   70  142    0\n",
            "6    20   93  128   61   56   85   39   13   71    4\n",
            "7    57   60   31   83  130    7   35   62   51  132\n",
            "8   100   11   76   78  149  100   86   54   74   32\n",
            "9   144   43  143    4  141   16   18   78  117   85\n",
            "10  127   33   53   26  106   87   54   13  115  116\n",
            "11    1   81  145   93  125   12  131    2   96   93\n",
            "12   79   76   72   37  147   50   43  145  116  136\n",
            "13  148   77   65   86   57  110  107   67   75   99\n",
            "14   64   44   85   59  121   62   22   37   64   13\n",
            "\n",
            "\n",
            "Uniques output:\n",
            "[\n",
            "  {\n",
            "    \"col\": \"A\",\n",
            "    \"unique_values\": \"[102, 106, 62, 101, 23, 67, 20, 57, 100, 144, 127, 1, 79, 148, 64]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"B\",\n",
            "    \"unique_values\": \"[101, 127, 138, 120, 125, 46, 93, 60, 11, 43, 33, 81, 76, 77, 44]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"C\",\n",
            "    \"unique_values\": \"[14, 120, 3, 104, 143, 128, 31, 76, 53, 145, 72, 65, 85]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"D\",\n",
            "    \"unique_values\": \"[66, 82, 139, 146, 119, 19, 61, 83, 78, 4, 26, 93, 37, 86, 59]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"E\",\n",
            "    \"unique_values\": \"[94, 80, 88, 49, 144, 10, 56, 130, 149, 141, 106, 125, 147, 57, 121]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"F\",\n",
            "    \"unique_values\": \"[71, 16, 131, 15, 22, 136, 85, 7, 100, 87, 12, 50, 110, 62]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"G\",\n",
            "    \"unique_values\": \"[50, 47, 44, 109, 4, 136, 39, 35, 86, 18, 54, 131, 43, 107, 22]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"H\",\n",
            "    \"unique_values\": \"[136, 74, 68, 20, 144, 70, 13, 62, 54, 78, 2, 145, 67, 37]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"I\",\n",
            "    \"unique_values\": \"[41, 5, 10, 61, 70, 142, 71, 51, 74, 117, 115, 96, 116, 75, 64]\"\n",
            "  },\n",
            "  {\n",
            "    \"col\": \"J\",\n",
            "    \"unique_values\": \"[23, 60, 110, 79, 87, 0, 4, 132, 32, 85, 116, 93, 136, 99, 13]\"\n",
            "  }\n",
            "]\n",
            "\n",
            "Total uniques in df:\n",
            "A    15\n",
            "B    15\n",
            "C    13\n",
            "D    15\n",
            "E    15\n",
            "F    14\n",
            "G    15\n",
            "H    14\n",
            "I    15\n",
            "J    15\n",
            "dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q3. Data Extraction**\n",
        "\n",
        "Given the following csv data, which of the following command(s) is/are the **correct** way to extract the mentioned columns in the order: **time, total_bill, tip**?\n",
        "\n",
        "**Options:**\n",
        "1. pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])\n",
        "2. df[['time', 'total_bill', 'tip']]\n",
        "3. df.loc[:, ['time', 'total_bill', 'tip']]\n",
        "4. df.iloc[:,0:2]"
      ],
      "metadata": {
        "id": "CK8d0jhCvKPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:***\n",
        "\n",
        "Options 1, 2, & 3\n",
        "* pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])\n",
        "* df[['time', 'total_bill', 'tip']]\n",
        "* df.loc[:, ['time', 'total_bill', 'tip']]"
      ],
      "metadata": {
        "id": "Zi9BpOJg3Ad9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if you want to download data from Google drive\n",
        "# !wget https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/276/original/tips.csv?1645193273 -O tips.csv\n",
        "# df = pd.read_csv('tips.csv')\n",
        "\n",
        "q3_csv_data = '''\n",
        "total_bill,tip,sex,smoker,day,time,size\n",
        "16.99,1.01,Female,No,Sun,Dinner,2\n",
        "10.34,1.66,Male,No,Sun,Dinner,3\n",
        "21.01,3.5,Male,No,Sun,Dinner,3\n",
        "23.68,3.31,Male,No,Sun,Dinner,2\n",
        "24.59,3.61,Female,No,Sun,Dinner,4\n",
        "25.29,4.71,Male,No,Sun,Dinner,4\n",
        "8.77,2.0,Male,No,Sun,Dinner,2\n",
        "26.88,3.12,Male,No,Sun,Dinner,4\n",
        "15.04,1.96,Male,No,Sun,Dinner,2\n",
        "14.78,3.23,Male,No,Sun,Dinner,2\n",
        "10.27,1.71,Male,No,Sun,Dinner,2\n",
        "35.26,5.0,Female,No,Sun,Dinner,4\n",
        "15.42,1.57,Male,No,Sun,Dinner,2\n",
        "18.43,3.0,Male,No,Sun,Dinner,4\n",
        "14.83,3.02,Female,No,Sun,Dinner,2\n",
        "21.58,3.92,Male,No,Sun,Dinner,2\n",
        "10.33,1.67,Female,No,Sun,Dinner,3\n",
        "16.29,3.71,Male,No,Sun,Dinner,3\n",
        "16.97,3.5,Female,No,Sun,Dinner,3\n",
        "20.65,3.35,Male,No,Sat,Dinner,3\n",
        "17.92,4.08,Male,No,Sat,Dinner,2\n",
        "20.29,2.75,Female,No,Sat,Dinner,2\n",
        "15.77,2.23,Female,No,Sat,Dinner,2\n",
        "39.42,7.58,Male,No,Sat,Dinner,4\n",
        "19.82,3.18,Male,No,Sat,Dinner,2\n",
        "17.81,2.34,Male,No,Sat,Dinner,4\n",
        "13.37,2.0,Male,No,Sat,Dinner,2\n",
        "12.69,2.0,Male,No,Sat,Dinner,2\n",
        "21.7,4.3,Male,No,Sat,Dinner,2\n",
        "19.65,3.0,Female,No,Sat,Dinner,2\n",
        "9.55,1.45,Male,No,Sat,Dinner,2\n",
        "18.35,2.5,Male,No,Sat,Dinner,4\n",
        "15.06,3.0,Female,No,Sat,Dinner,2\n",
        "20.69,2.45,Female,No,Sat,Dinner,4\n",
        "17.78,3.27,Male,No,Sat,Dinner,2\n",
        "24.06,3.6,Male,No,Sat,Dinner,3\n",
        "16.31,2.0,Male,No,Sat,Dinner,3\n",
        "16.93,3.07,Female,No,Sat,Dinner,3\n",
        "18.69,2.31,Male,No,Sat,Dinner,3\n",
        "31.27,5.0,Male,No,Sat,Dinner,3\n",
        "16.04,2.24,Male,No,Sat,Dinner,3\n",
        "17.46,2.54,Male,No,Sun,Dinner,2\n",
        "13.94,3.06,Male,No,Sun,Dinner,2\n",
        "9.68,1.32,Male,No,Sun,Dinner,2\n",
        "30.4,5.6,Male,No,Sun,Dinner,4\n",
        "18.29,3.0,Male,No,Sun,Dinner,2\n",
        "22.23,5.0,Male,No,Sun,Dinner,2\n",
        "32.4,6.0,Male,No,Sun,Dinner,4\n",
        "28.55,2.05,Male,No,Sun,Dinner,3\n",
        "18.04,3.0,Male,No,Sun,Dinner,2\n",
        "12.54,2.5,Male,No,Sun,Dinner,2\n",
        "10.29,2.6,Female,No,Sun,Dinner,2\n",
        "34.81,5.2,Female,No,Sun,Dinner,4\n",
        "9.94,1.56,Male,No,Sun,Dinner,2\n",
        "25.56,4.34,Male,No,Sun,Dinner,4\n",
        "19.49,3.51,Male,No,Sun,Dinner,2\n",
        "38.01,3.0,Male,Yes,Sat,Dinner,4\n",
        "26.41,1.5,Female,No,Sat,Dinner,2\n",
        "11.24,1.76,Male,Yes,Sat,Dinner,2\n",
        "48.27,6.73,Male,No,Sat,Dinner,4\n",
        "20.29,3.21,Male,Yes,Sat,Dinner,2\n",
        "13.81,2.0,Male,Yes,Sat,Dinner,2\n",
        "11.02,1.98,Male,Yes,Sat,Dinner,2\n",
        "18.29,3.76,Male,Yes,Sat,Dinner,4\n",
        "17.59,2.64,Male,No,Sat,Dinner,3\n",
        "20.08,3.15,Male,No,Sat,Dinner,3\n",
        "16.45,2.47,Female,No,Sat,Dinner,2\n",
        "3.07,1.0,Female,Yes,Sat,Dinner,1\n",
        "20.23,2.01,Male,No,Sat,Dinner,2\n",
        "15.01,2.09,Male,Yes,Sat,Dinner,2\n",
        "12.02,1.97,Male,No,Sat,Dinner,2\n",
        "17.07,3.0,Female,No,Sat,Dinner,3\n",
        "26.86,3.14,Female,Yes,Sat,Dinner,2\n",
        "25.28,5.0,Female,Yes,Sat,Dinner,2\n",
        "14.73,2.2,Female,No,Sat,Dinner,2\n",
        "10.51,1.25,Male,No,Sat,Dinner,2\n",
        "17.92,3.08,Male,Yes,Sat,Dinner,2\n",
        "27.2,4.0,Male,No,Thur,Lunch,4\n",
        "22.76,3.0,Male,No,Thur,Lunch,2\n",
        "17.29,2.71,Male,No,Thur,Lunch,2\n",
        "19.44,3.0,Male,Yes,Thur,Lunch,2\n",
        "16.66,3.4,Male,No,Thur,Lunch,2\n",
        "10.07,1.83,Female,No,Thur,Lunch,1\n",
        "32.68,5.0,Male,Yes,Thur,Lunch,2\n",
        "15.98,2.03,Male,No,Thur,Lunch,2\n",
        "34.83,5.17,Female,No,Thur,Lunch,4\n",
        "13.03,2.0,Male,No,Thur,Lunch,2\n",
        "18.28,4.0,Male,No,Thur,Lunch,2\n",
        "24.71,5.85,Male,No,Thur,Lunch,2\n",
        "21.16,3.0,Male,No,Thur,Lunch,2\n",
        "28.97,3.0,Male,Yes,Fri,Dinner,2\n",
        "22.49,3.5,Male,No,Fri,Dinner,2\n",
        "5.75,1.0,Female,Yes,Fri,Dinner,2\n",
        "16.32,4.3,Female,Yes,Fri,Dinner,2\n",
        "22.75,3.25,Female,No,Fri,Dinner,2\n",
        "40.17,4.73,Male,Yes,Fri,Dinner,4\n",
        "27.28,4.0,Male,Yes,Fri,Dinner,2\n",
        "12.03,1.5,Male,Yes,Fri,Dinner,2\n",
        "21.01,3.0,Male,Yes,Fri,Dinner,2\n",
        "12.46,1.5,Male,No,Fri,Dinner,2\n",
        "11.35,2.5,Female,Yes,Fri,Dinner,2\n",
        "15.38,3.0,Female,Yes,Fri,Dinner,2\n",
        "44.3,2.5,Female,Yes,Sat,Dinner,3\n",
        "22.42,3.48,Female,Yes,Sat,Dinner,2\n",
        "20.92,4.08,Female,No,Sat,Dinner,2\n",
        "15.36,1.64,Male,Yes,Sat,Dinner,2\n",
        "20.49,4.06,Male,Yes,Sat,Dinner,2\n",
        "25.21,4.29,Male,Yes,Sat,Dinner,2\n",
        "18.24,3.76,Male,No,Sat,Dinner,2\n",
        "14.31,4.0,Female,Yes,Sat,Dinner,2\n",
        "14.0,3.0,Male,No,Sat,Dinner,2\n",
        "7.25,1.0,Female,No,Sat,Dinner,1\n",
        "38.07,4.0,Male,No,Sun,Dinner,3\n",
        "23.95,2.55,Male,No,Sun,Dinner,2\n",
        "25.71,4.0,Female,No,Sun,Dinner,3\n",
        "17.31,3.5,Female,No,Sun,Dinner,2\n",
        "29.93,5.07,Male,No,Sun,Dinner,4\n",
        "10.65,1.5,Female,No,Thur,Lunch,2\n",
        "12.43,1.8,Female,No,Thur,Lunch,2\n",
        "24.08,2.92,Female,No,Thur,Lunch,4\n",
        "11.69,2.31,Male,No,Thur,Lunch,2\n",
        "13.42,1.68,Female,No,Thur,Lunch,2\n",
        "14.26,2.5,Male,No,Thur,Lunch,2\n",
        "15.95,2.0,Male,No,Thur,Lunch,2\n",
        "12.48,2.52,Female,No,Thur,Lunch,2\n",
        "29.8,4.2,Female,No,Thur,Lunch,6\n",
        "8.52,1.48,Male,No,Thur,Lunch,2\n",
        "14.52,2.0,Female,No,Thur,Lunch,2\n",
        "11.38,2.0,Female,No,Thur,Lunch,2\n",
        "22.82,2.18,Male,No,Thur,Lunch,3\n",
        "19.08,1.5,Male,No,Thur,Lunch,2\n",
        "20.27,2.83,Female,No,Thur,Lunch,2\n",
        "11.17,1.5,Female,No,Thur,Lunch,2\n",
        "12.26,2.0,Female,No,Thur,Lunch,2\n",
        "18.26,3.25,Female,No,Thur,Lunch,2\n",
        "8.51,1.25,Female,No,Thur,Lunch,2\n",
        "10.33,2.0,Female,No,Thur,Lunch,2\n",
        "14.15,2.0,Female,No,Thur,Lunch,2\n",
        "16.0,2.0,Male,Yes,Thur,Lunch,2\n",
        "13.16,2.75,Female,No,Thur,Lunch,2\n",
        "17.47,3.5,Female,No,Thur,Lunch,2\n",
        "34.3,6.7,Male,No,Thur,Lunch,6\n",
        "41.19,5.0,Male,No,Thur,Lunch,5\n",
        "27.05,5.0,Female,No,Thur,Lunch,6\n",
        "16.43,2.3,Female,No,Thur,Lunch,2\n",
        "8.35,1.5,Female,No,Thur,Lunch,2\n",
        "18.64,1.36,Female,No,Thur,Lunch,3\n",
        "11.87,1.63,Female,No,Thur,Lunch,2\n",
        "9.78,1.73,Male,No,Thur,Lunch,2\n",
        "7.51,2.0,Male,No,Thur,Lunch,2\n",
        "14.07,2.5,Male,No,Sun,Dinner,2\n",
        "13.13,2.0,Male,No,Sun,Dinner,2\n",
        "17.26,2.74,Male,No,Sun,Dinner,3\n",
        "24.55,2.0,Male,No,Sun,Dinner,4\n",
        "19.77,2.0,Male,No,Sun,Dinner,4\n",
        "29.85,5.14,Female,No,Sun,Dinner,5\n",
        "48.17,5.0,Male,No,Sun,Dinner,6\n",
        "25.0,3.75,Female,No,Sun,Dinner,4\n",
        "13.39,2.61,Female,No,Sun,Dinner,2\n",
        "16.49,2.0,Male,No,Sun,Dinner,4\n",
        "21.5,3.5,Male,No,Sun,Dinner,4\n",
        "12.66,2.5,Male,No,Sun,Dinner,2\n",
        "16.21,2.0,Female,No,Sun,Dinner,3\n",
        "13.81,2.0,Male,No,Sun,Dinner,2\n",
        "17.51,3.0,Female,Yes,Sun,Dinner,2\n",
        "24.52,3.48,Male,No,Sun,Dinner,3\n",
        "20.76,2.24,Male,No,Sun,Dinner,2\n",
        "31.71,4.5,Male,No,Sun,Dinner,4\n",
        "10.59,1.61,Female,Yes,Sat,Dinner,2\n",
        "10.63,2.0,Female,Yes,Sat,Dinner,2\n",
        "50.81,10.0,Male,Yes,Sat,Dinner,3\n",
        "15.81,3.16,Male,Yes,Sat,Dinner,2\n",
        "7.25,5.15,Male,Yes,Sun,Dinner,2\n",
        "31.85,3.18,Male,Yes,Sun,Dinner,2\n",
        "16.82,4.0,Male,Yes,Sun,Dinner,2\n",
        "32.9,3.11,Male,Yes,Sun,Dinner,2\n",
        "17.89,2.0,Male,Yes,Sun,Dinner,2\n",
        "14.48,2.0,Male,Yes,Sun,Dinner,2\n",
        "9.6,4.0,Female,Yes,Sun,Dinner,2\n",
        "34.63,3.55,Male,Yes,Sun,Dinner,2\n",
        "34.65,3.68,Male,Yes,Sun,Dinner,4\n",
        "23.33,5.65,Male,Yes,Sun,Dinner,2\n",
        "45.35,3.5,Male,Yes,Sun,Dinner,3\n",
        "23.17,6.5,Male,Yes,Sun,Dinner,4\n",
        "40.55,3.0,Male,Yes,Sun,Dinner,2\n",
        "20.69,5.0,Male,No,Sun,Dinner,5\n",
        "20.9,3.5,Female,Yes,Sun,Dinner,3\n",
        "30.46,2.0,Male,Yes,Sun,Dinner,5\n",
        "18.15,3.5,Female,Yes,Sun,Dinner,3\n",
        "23.1,4.0,Male,Yes,Sun,Dinner,3\n",
        "15.69,1.5,Male,Yes,Sun,Dinner,2\n",
        "19.81,4.19,Female,Yes,Thur,Lunch,2\n",
        "28.44,2.56,Male,Yes,Thur,Lunch,2\n",
        "15.48,2.02,Male,Yes,Thur,Lunch,2\n",
        "16.58,4.0,Male,Yes,Thur,Lunch,2\n",
        "7.56,1.44,Male,No,Thur,Lunch,2\n",
        "10.34,2.0,Male,Yes,Thur,Lunch,2\n",
        "43.11,5.0,Female,Yes,Thur,Lunch,4\n",
        "13.0,2.0,Female,Yes,Thur,Lunch,2\n",
        "13.51,2.0,Male,Yes,Thur,Lunch,2\n",
        "18.71,4.0,Male,Yes,Thur,Lunch,3\n",
        "12.74,2.01,Female,Yes,Thur,Lunch,2\n",
        "13.0,2.0,Female,Yes,Thur,Lunch,2\n",
        "16.4,2.5,Female,Yes,Thur,Lunch,2\n",
        "20.53,4.0,Male,Yes,Thur,Lunch,4\n",
        "16.47,3.23,Female,Yes,Thur,Lunch,3\n",
        "26.59,3.41,Male,Yes,Sat,Dinner,3\n",
        "38.73,3.0,Male,Yes,Sat,Dinner,4\n",
        "24.27,2.03,Male,Yes,Sat,Dinner,2\n",
        "12.76,2.23,Female,Yes,Sat,Dinner,2\n",
        "30.06,2.0,Male,Yes,Sat,Dinner,3\n",
        "25.89,5.16,Male,Yes,Sat,Dinner,4\n",
        "48.33,9.0,Male,No,Sat,Dinner,4\n",
        "13.27,2.5,Female,Yes,Sat,Dinner,2\n",
        "28.17,6.5,Female,Yes,Sat,Dinner,3\n",
        "12.9,1.1,Female,Yes,Sat,Dinner,2\n",
        "28.15,3.0,Male,Yes,Sat,Dinner,5\n",
        "11.59,1.5,Male,Yes,Sat,Dinner,2\n",
        "7.74,1.44,Male,Yes,Sat,Dinner,2\n",
        "30.14,3.09,Female,Yes,Sat,Dinner,4\n",
        "12.16,2.2,Male,Yes,Fri,Lunch,2\n",
        "13.42,3.48,Female,Yes,Fri,Lunch,2\n",
        "8.58,1.92,Male,Yes,Fri,Lunch,1\n",
        "15.98,3.0,Female,No,Fri,Lunch,3\n",
        "13.42,1.58,Male,Yes,Fri,Lunch,2\n",
        "16.27,2.5,Female,Yes,Fri,Lunch,2\n",
        "10.09,2.0,Female,Yes,Fri,Lunch,2\n",
        "20.45,3.0,Male,No,Sat,Dinner,4\n",
        "13.28,2.72,Male,No,Sat,Dinner,2\n",
        "22.12,2.88,Female,Yes,Sat,Dinner,2\n",
        "24.01,2.0,Male,Yes,Sat,Dinner,4\n",
        "15.69,3.0,Male,Yes,Sat,Dinner,3\n",
        "11.61,3.39,Male,No,Sat,Dinner,2\n",
        "10.77,1.47,Male,No,Sat,Dinner,2\n",
        "15.53,3.0,Male,Yes,Sat,Dinner,2\n",
        "10.07,1.25,Male,No,Sat,Dinner,2\n",
        "12.6,1.0,Male,Yes,Sat,Dinner,2\n",
        "32.83,1.17,Male,Yes,Sat,Dinner,2\n",
        "35.83,4.67,Female,No,Sat,Dinner,3\n",
        "29.03,5.92,Male,No,Sat,Dinner,3\n",
        "27.18,2.0,Female,Yes,Sat,Dinner,2\n",
        "22.67,2.0,Male,Yes,Sat,Dinner,2\n",
        "17.82,1.75,Male,No,Sat,Dinner,2\n",
        "18.78,3.0,Female,No,Thur,Dinner,2\n",
        "'''"
      ],
      "metadata": {
        "id": "0ghb-TUE0SHx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Use this if you want to download data from Google drive\n",
        "# !wget https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/276/original/tips.csv?1645193273 -O tips.csv\n",
        "# df = pd.read_csv('tips.csv')\n",
        "df = pd.read_csv(io.StringIO(q3_csv_data))\n",
        "print(df)\n",
        "\n",
        "print(f\"\"\"\n",
        "pd.DataFrame(df, columns=['time', 'total_bill', 'tip']) =\n",
        "{pd.DataFrame(df, columns=['time', 'total_bill', 'tip'])}\n",
        "\"\"\", end = \"\\n\")\n",
        "\n",
        "print(f\"\"\"\n",
        "df[['time', 'total_bill', 'tip']] =\"\n",
        "{df[['time', 'total_bill', 'tip']]}\n",
        "\"\"\", end = \"\\n\")\n",
        "\n",
        "print(f\"\"\"\n",
        "df.loc[:, ['time', 'total_bill', 'tip']] =\n",
        "{df.loc[:, ['time', 'total_bill', 'tip']]}\n",
        "\"\"\", end = \"\\n\")\n",
        "\n",
        "print(f\"\"\"\n",
        "df.iloc[:,0:2] =\n",
        "{df.iloc[:,0:2]}\n",
        "\"\"\", end = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U1MapXp0qKO",
        "outputId": "bd3ee8ed-a202-4eeb-b4a4-7a5d396685c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     total_bill   tip     sex smoker   day    time  size\n",
            "0         16.99  1.01  Female     No   Sun  Dinner     2\n",
            "1         10.34  1.66    Male     No   Sun  Dinner     3\n",
            "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
            "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
            "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
            "..          ...   ...     ...    ...   ...     ...   ...\n",
            "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
            "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
            "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
            "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
            "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
            "\n",
            "[244 rows x 7 columns]\n",
            "\n",
            "pd.DataFrame(df, columns=['time', 'total_bill', 'tip']) =\n",
            "       time  total_bill   tip\n",
            "0    Dinner       16.99  1.01\n",
            "1    Dinner       10.34  1.66\n",
            "2    Dinner       21.01  3.50\n",
            "3    Dinner       23.68  3.31\n",
            "4    Dinner       24.59  3.61\n",
            "..      ...         ...   ...\n",
            "239  Dinner       29.03  5.92\n",
            "240  Dinner       27.18  2.00\n",
            "241  Dinner       22.67  2.00\n",
            "242  Dinner       17.82  1.75\n",
            "243  Dinner       18.78  3.00\n",
            "\n",
            "[244 rows x 3 columns]\n",
            "\n",
            "\n",
            "df[['time', 'total_bill', 'tip']] =\"\n",
            "       time  total_bill   tip\n",
            "0    Dinner       16.99  1.01\n",
            "1    Dinner       10.34  1.66\n",
            "2    Dinner       21.01  3.50\n",
            "3    Dinner       23.68  3.31\n",
            "4    Dinner       24.59  3.61\n",
            "..      ...         ...   ...\n",
            "239  Dinner       29.03  5.92\n",
            "240  Dinner       27.18  2.00\n",
            "241  Dinner       22.67  2.00\n",
            "242  Dinner       17.82  1.75\n",
            "243  Dinner       18.78  3.00\n",
            "\n",
            "[244 rows x 3 columns]\n",
            "\n",
            "\n",
            "df.loc[:, ['time', 'total_bill', 'tip']] =\n",
            "       time  total_bill   tip\n",
            "0    Dinner       16.99  1.01\n",
            "1    Dinner       10.34  1.66\n",
            "2    Dinner       21.01  3.50\n",
            "3    Dinner       23.68  3.31\n",
            "4    Dinner       24.59  3.61\n",
            "..      ...         ...   ...\n",
            "239  Dinner       29.03  5.92\n",
            "240  Dinner       27.18  2.00\n",
            "241  Dinner       22.67  2.00\n",
            "242  Dinner       17.82  1.75\n",
            "243  Dinner       18.78  3.00\n",
            "\n",
            "[244 rows x 3 columns]\n",
            "\n",
            "\n",
            "df.iloc[:,0:2] =\n",
            "     total_bill   tip\n",
            "0         16.99  1.01\n",
            "1         10.34  1.66\n",
            "2         21.01  3.50\n",
            "3         23.68  3.31\n",
            "4         24.59  3.61\n",
            "..          ...   ...\n",
            "239       29.03  5.92\n",
            "240       27.18  2.00\n",
            "241       22.67  2.00\n",
            "242       17.82  1.75\n",
            "243       18.78  3.00\n",
            "\n",
            "[244 rows x 2 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q4. loc and iloc**\n",
        "\n",
        "Given, a dataframe df:\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Name</th>\n",
        "      <th>Gender</th>\n",
        "      <th>Profession</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>Jim</td>\n",
        "      <td>M</td>\n",
        "      <td>Athlete</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>Carry</td>\n",
        "      <td>F</td>\n",
        "      <td>Tech</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Chris</td>\n",
        "      <td>M</td>\n",
        "      <td>Cricketer</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>Morris</td>\n",
        "      <td>M</td>\n",
        "      <td>Actor</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "The following codes are executed on the data frame df\n",
        "\n",
        "```python\n",
        "df.iloc[:2,:2]\n",
        "#line a\n",
        "df.loc[:2,\"Name\":\"Profession\"]\n",
        "#line b\n",
        "```\n",
        "\n",
        "From the above-given information, mark the option which is true regarding the following statements.\n",
        "\n",
        "1. For line a, the output is the first two rows with the three columns [\"Name\", \"Gender\", \"Profession\"].\n",
        "\n",
        "2. For line a, the output is the first two rows with the two columns [\"Name\", \"Gender\"].\n",
        "\n",
        "3. For line b, the output is the row with labels 0, 1, and 2 with the columns [\"Name\", \"Gender\", \"Profession\"].\n",
        "\n",
        "4. For line b, TypeError will be generated."
      ],
      "metadata": {
        "id": "U0RbXV2pvoJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Options 2 & 3:\n",
        "\n",
        "* For line a, the output is the first two rows with the two columns [\"Name\", \"Gender\"].\n",
        "* For line b, the output is the row with labels 0, 1, and 2 with the columns [\"Name\", \"Gender\", \"Profession\"]."
      ],
      "metadata": {
        "id": "8Z4709q202IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'Name':['Jim', 'Carry', 'Chris', 'Morris'],\n",
        "    'Gender': ['M', 'F', 'M', 'M'],\n",
        "    'Profession': ['Athlete', 'Tech', 'Cricketer', 'Actor']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.iloc[:2,:2]\n",
        "#line a\n",
        "df.loc[:2,\"Name\":\"Profession\"]\n",
        "#line b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6TdJTqUE6sQo",
        "outputId": "d3e2482d-ee18-4d00-f0e8-5cffcceee43d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Name Gender Profession\n",
              "0    Jim      M    Athlete\n",
              "1  Carry      F       Tech\n",
              "2  Chris      M  Cricketer"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-542d72be-bb76-4dd0-b6aa-1b66def2b974\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Profession</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jim</td>\n",
              "      <td>M</td>\n",
              "      <td>Athlete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Carry</td>\n",
              "      <td>F</td>\n",
              "      <td>Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chris</td>\n",
              "      <td>M</td>\n",
              "      <td>Cricketer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-542d72be-bb76-4dd0-b6aa-1b66def2b974')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-542d72be-bb76-4dd0-b6aa-1b66def2b974 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-542d72be-bb76-4dd0-b6aa-1b66def2b974');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#line b\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Jim\",\n          \"Carry\",\n          \"Chris\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"F\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profession\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Athlete\",\n          \"Tech\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q5. Select the required data**\n",
        "\n",
        "Given the dataset of 10 car models and their respective features, what would be the correct code to get following result:\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>model</th>\n",
        "      <th>disp</th>\n",
        "      <th>hp</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>Mazda RX4 Wag</td>\n",
        "      <td>160.0</td>\n",
        "      <td>110</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Datsun 710</td>\n",
        "      <td>108.0</td>\n",
        "      <td>93</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>Hornet 4 Drive</td>\n",
        "      <td>258.0</td>\n",
        "      <td>110</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>Hornet Sportabout</td>\n",
        "      <td>360.0</td>\n",
        "      <td>175</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ],
      "metadata": {
        "id": "e0Y8F_HZmzs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if you want to download data from Google drive\n",
        "# !gdown 1UcWItyfVGL-mPlnR002bDRx_rdkSbgGq\n",
        "# df = pd.read_csv('mtcars.csv')\n",
        "\n",
        "q5_csv_data = f'''\n",
        "model,mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb\n",
        "Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4\n",
        "Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4\n",
        "Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1\n",
        "Hornet 4 Drive,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1\n",
        "Hornet Sportabout,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2\n",
        "Valiant,18.1,6,225,105,2.76,3.46,20.22,1,0,3,1\n",
        "Duster 360,14.3,8,360,245,3.21,3.57,15.84,0,0,3,4\n",
        "Merc 240D,24.4,4,146.7,62,3.69,3.19,20,1,0,4,2\n",
        "Merc 230,22.8,4,140.8,95,3.92,3.15,22.9,1,0,4,2\n",
        "Merc 280,19.2,6,167.6,123,3.92,3.44,18.3,1,0,4,4\n",
        "Merc 280C,17.8,6,167.6,123,3.92,3.44,18.9,1,0,4,4\n",
        "Merc 450SE,16.4,8,275.8,180,3.07,4.07,17.4,0,0,3,3\n",
        "Merc 450SL,17.3,8,275.8,180,3.07,3.73,17.6,0,0,3,3\n",
        "Merc 450SLC,15.2,8,275.8,180,3.07,3.78,18,0,0,3,3\n",
        "Cadillac Fleetwood,10.4,8,472,205,2.93,5.25,17.98,0,0,3,4\n",
        "Lincoln Continental,10.4,8,460,215,3,5.424,17.82,0,0,3,4\n",
        "Chrysler Imperial,14.7,8,440,230,3.23,5.345,17.42,0,0,3,4\n",
        "Fiat 128,32.4,4,78.7,66,4.08,2.2,19.47,1,1,4,1\n",
        "Honda Civic,30.4,4,75.7,52,4.93,1.615,18.52,1,1,4,2\n",
        "Toyota Corolla,33.9,4,71.1,65,4.22,1.835,19.9,1,1,4,1\n",
        "Toyota Corona,21.5,4,120.1,97,3.7,2.465,20.01,1,0,3,1\n",
        "Dodge Challenger,15.5,8,318,150,2.76,3.52,16.87,0,0,3,2\n",
        "AMC Javelin,15.2,8,304,150,3.15,3.435,17.3,0,0,3,2\n",
        "Camaro Z28,13.3,8,350,245,3.73,3.84,15.41,0,0,3,4\n",
        "Pontiac Firebird,19.2,8,400,175,3.08,3.845,17.05,0,0,3,2\n",
        "Fiat X1-9,27.3,4,79,66,4.08,1.935,18.9,1,1,4,1\n",
        "Porsche 914-2,26,4,120.3,91,4.43,2.14,16.7,0,1,5,2\n",
        "Lotus Europa,30.4,4,95.1,113,3.77,1.513,16.9,1,1,5,2\n",
        "Ford Pantera L,15.8,8,351,264,4.22,3.17,14.5,0,1,5,4\n",
        "Ferrari Dino,19.7,6,145,175,3.62,2.77,15.5,0,1,5,6\n",
        "Maserati Bora,15,8,301,335,3.54,3.57,14.6,0,1,5,8\n",
        "Volvo 142E,21.4,4,121,109,4.11,2.78,18.6,1,1,4,2\n",
        "'''"
      ],
      "metadata": {
        "id": "gNZERouBUa0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "# Use this if you want to download data from Google drive\n",
        "# !gdown 1UcWItyfVGL-mPlnR002bDRx_rdkSbgGq\n",
        "# data = pd.read_csv('mtcars.csv')\n",
        "\n",
        "data = pd.read_csv(io.StringIO(q5_csv_data))\n",
        "data.iloc[1:5, [0, 3, 4]].to_html()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "kwzVfX8EU1_X",
        "outputId": "5e2c5f11-c69c-4a87-a502-a3918e1ffc08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>model</th>\\n      <th>disp</th>\\n      <th>hp</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>1</th>\\n      <td>Mazda RX4 Wag</td>\\n      <td>160.0</td>\\n      <td>110</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Datsun 710</td>\\n      <td>108.0</td>\\n      <td>93</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Hornet 4 Drive</td>\\n      <td>258.0</td>\\n      <td>110</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Hornet Sportabout</td>\\n      <td>360.0</td>\\n      <td>175</td>\\n    </tr>\\n  </tbody>\\n</table>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AQ1. The selected rows**\n",
        "\n",
        "**Problem Description:**\n",
        "\n",
        "Given a dataframe containing transaction data sorted in order of transaction date, and row range r1 (start index) and r2 (end index).\n",
        "\n",
        "* Filter out the rows between r1 and r2 (r2 is exclusive).\n",
        "* Complete the function select_rows() to do the same, with dataframe and r1 and r2 values provided to the function.\n",
        "* Return only the \"name\" and \"amt\" columns from the filtered dataframe.\n",
        "\n",
        "**Sample Input:**\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>date</th>\n",
        "      <th>name</th>\n",
        "      <th>amt</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>2020-01-10</td>\n",
        "      <td>Himanshu</td>\n",
        "      <td>100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2020-07-01</td>\n",
        "      <td>Robert</td>\n",
        "      <td>200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>2020-08-01</td>\n",
        "      <td>Karie</td>\n",
        "      <td>400</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>2020-03-02</td>\n",
        "      <td>Rohan</td>\n",
        "      <td>150</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>2020-01-03</td>\n",
        "      <td>John</td>\n",
        "      <td>300</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "**Sample Output:**\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>amt</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>Robert</td>\n",
        "      <td>200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Karie</td>\n",
        "      <td>400</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ],
      "metadata": {
        "id": "ghV8A9rpoeot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aq1_csv_data = f'''\n",
        "date,name,amt\n",
        "2020-01-10,Himanshu,100\n",
        "2020-07-01,Robert,200\n",
        "2020-08-01,Karie,400\n",
        "2020-03-02,Rohan,150\n",
        "2020-01-03,John,300\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ruF4Otbb-Ti-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def select_rows(df, r1, r2):\n",
        "    '''\n",
        "    input:\n",
        "    df -> the dataframe provided to the function\n",
        "    r1 -> the starting index of the rows to be selected\n",
        "    r2 -> the ending index of the rows to be selected\n",
        "\n",
        "    output:\n",
        "    df_new -> the selected rows of the dataframe\n",
        "    '''\n",
        "\n",
        "    # Select the rows r1 to r2\n",
        "    df_selected = df.iloc[r1:r2]\n",
        "\n",
        "    # Select the columns \"name\" and \"amt\"\n",
        "    df_new = df_selected[[\"name\", \"amt\"]]\n",
        "\n",
        "    return df_new\n",
        "\n",
        "df = pd.read_csv(io.StringIO(aq1_csv_data))\n",
        "df_new = select_rows(df, 1, 3)\n",
        "print(df_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0FunEBVX1N1",
        "outputId": "e370eba0-93d8-4501-e81f-a5dba56fd47c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     name  amt\n",
            "1  Robert  200\n",
            "2   Karie  400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2. Display all the rows**\n",
        "\n",
        "Given the dataset in Q5 of car models and their respective features, What would be the correct code to print every row of the \"disp\" column?\n",
        "\n",
        "**Options:**\n",
        "\n",
        "1. data.loc[:,'disp']\n",
        "2. data['disp']\n",
        "3. data.iloc[:,'disp']\n",
        "4. data.loc['disp',:]"
      ],
      "metadata": {
        "id": "Im-sdqqC-ZcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "data = pd.read_csv(io.StringIO(q5_csv_data))\n",
        "print(f\"\"\"\n",
        "data.loc[:,'disp'] =\n",
        "{data.loc[:,'disp']}\n",
        "\"\"\")\n",
        "\n",
        "print(f\"\"\"\n",
        "data['disp'] =\n",
        "{data['disp']}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_QEPGKx4tks",
        "outputId": "79819127-1512-4d1a-823a-c2b9e130881e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "data.loc[:,'disp'] =\n",
            "0     160.0\n",
            "1     160.0\n",
            "2     108.0\n",
            "3     258.0\n",
            "4     360.0\n",
            "5     225.0\n",
            "6     360.0\n",
            "7     146.7\n",
            "8     140.8\n",
            "9     167.6\n",
            "10    167.6\n",
            "11    275.8\n",
            "12    275.8\n",
            "13    275.8\n",
            "14    472.0\n",
            "15    460.0\n",
            "16    440.0\n",
            "17     78.7\n",
            "18     75.7\n",
            "19     71.1\n",
            "20    120.1\n",
            "21    318.0\n",
            "22    304.0\n",
            "23    350.0\n",
            "24    400.0\n",
            "25     79.0\n",
            "26    120.3\n",
            "27     95.1\n",
            "28    351.0\n",
            "29    145.0\n",
            "30    301.0\n",
            "31    121.0\n",
            "Name: disp, dtype: float64\n",
            "\n",
            "\n",
            "data['disp'] =\n",
            "0     160.0\n",
            "1     160.0\n",
            "2     108.0\n",
            "3     258.0\n",
            "4     360.0\n",
            "5     225.0\n",
            "6     360.0\n",
            "7     146.7\n",
            "8     140.8\n",
            "9     167.6\n",
            "10    167.6\n",
            "11    275.8\n",
            "12    275.8\n",
            "13    275.8\n",
            "14    472.0\n",
            "15    460.0\n",
            "16    440.0\n",
            "17     78.7\n",
            "18     75.7\n",
            "19     71.1\n",
            "20    120.1\n",
            "21    318.0\n",
            "22    304.0\n",
            "23    350.0\n",
            "24    400.0\n",
            "25     79.0\n",
            "26    120.3\n",
            "27     95.1\n",
            "28    351.0\n",
            "29    145.0\n",
            "30    301.0\n",
            "31    121.0\n",
            "Name: disp, dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AQ3. Satisfied customers**\n",
        "\n",
        "Given a dataframe\n",
        "\n",
        "Return a subset of the dataframe with records having **rating >= 6**, containing the columns **\"profession\"**, **\"gender\"** and **\"age\"** only.\n",
        "\n",
        "**Sample Input:**\n",
        "```json\n",
        "{'name':[\"Sam\",\"Roma\",\"Mark\"], \"profession\":['dev','mle','Data scientist'],\"gender\":['male','female','male'], \"age\":[21,20,25],\"review\":['No comments','hardworker','need improvement'],\"rating\":[10,5,7]}\n",
        "```\n",
        "\n",
        "**Sample Output:**\n",
        "\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>profession</th>\n",
        "      <th>gender</th>\n",
        "      <th>age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>dev</td>\n",
        "      <td>male</td>\n",
        "      <td>21</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Data scientist</td>\n",
        "      <td>male</td>\n",
        "      <td>25</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "e2szcx31-mr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def filtered_customers(df):\n",
        "    ''' df is a dataframe with columns ['name', 'profession', 'gender', 'age', 'review', 'rating']\n",
        "        Output -> A dataframe with required rows is expected to be returned'''\n",
        "\n",
        "    # YOUR CODE GOES HERE\n",
        "    # Filter the dataframe having ratings>=6 and choose the required columns\n",
        "    new_df = df[df['rating'] >= 6][['profession', 'gender', 'age']]\n",
        "\n",
        "    return new_df\n",
        "\n",
        "data = {\n",
        "    'name': [\"Sam\",\"Roma\",\"Mark\"],\n",
        "    'profession': ['dev','mle','Data scientist'],\n",
        "    'gender': ['male','female','male'],\n",
        "    'age': [21,20,25],\n",
        "    'review': ['No comments','hardworker','need improvement'],\n",
        "    'rating':[ 10,5,7]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(filtered_customers(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX5780S9biI3",
        "outputId": "8b2ea262-8414-420f-86b9-794f60c137e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       profession gender  age\n",
            "0             dev   male   21\n",
            "2  Data scientist   male   25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AQ4. Correct way to form a dataframe?**\n",
        "\n",
        "Which of these would be the correct way to create a dataframe?\n",
        "\n",
        "a.\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame([[1, 2], [\"Ram\", \"Shyam\"], [\"IT\", \"Ops\"]], columns = [\"emp_id\", \"name\", \"dept\"])\n",
        "```\n",
        "\n",
        "b.\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame([[1, \"Ram\", \"IT\"], [2, \"Shyam\", \"Ops\"]], columns = [\"emp_id\", \"name\", \"dept\"])\n",
        "```\n",
        "\n",
        "c.\n",
        "\n",
        "```\n",
        "df = pd.DataFrame([1, \"Ram\", \"IT\"], columns = [\"emp_id\", \"name\", \"dept\"])\n",
        "```\n",
        "\n",
        "d.\n",
        "\n",
        "```\n",
        "df = pd.DataFrame({'emp_id':[1, 2], 'name': ['Ram', 'Shyam'], 'dept':['IT', 'Ops']})\n",
        "```"
      ],
      "metadata": {
        "id": "9ziGnVfR_J41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ans:**\n",
        "\n",
        "Option b & d"
      ],
      "metadata": {
        "id": "wG0MTCK55ilq"
      }
    }
  ]
}