# -*- coding: utf-8 -*-
"""4-Notes-LR-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dpALxl5_v9ZN6wmA9fyXb6eG5OKrUWX9

## Content

- Feature Scaling
- ADj. R-Square
- Intro to Stats Model

- Linearity Assumption

## How feature scaling helps easier model training?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/747/original/z.png?1705225934' width=800>

<img src="https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/085/918/original/download_%281%29.png?1723533045" width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/085/923/original/download_%2811%29.jpeg?1723534701' width=800>

## Problems with R-squared, Adjusted R-squared

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/748/original/z.png?1705225962' width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/749/original/z.png?1705225995' width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/750/original/z.png?1705226069' width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/751/original/z.png?1705226101' width=800>

## Intro to statsmodel

Let's check a library called `statsmodel` which we will be using throughout this lecture.

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/753/original/z.png?1705226176' width=800>

First we will download our data.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm

!gdown 1UpLnYA48Vy_lGUMMLG-uQE1gf_Je12Lh

df = pd.read_csv('cars24-car-price-clean.csv')
df.head()

y=df[['selling_price']]
X=df.drop('selling_price', axis=1)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

y_train = np.array(y_train)

"""Now, let's train our model on the data."""

X_sm = sm.add_constant(X_train)  # Statmodels default is without intercept, to add intercept we need to add constant.

model = sm.OLS(y_train, X_sm)
results = model.fit()

# Print the summary statistics of the model
print(results.summary())

"""Let's look at few of the variables in this table:

- Dep. Variable: This column displays the name of the dependent variable being predicted in the regression.

- Model: It provides a concise representation of the model type and method used, such as "OLS" (Ordinary Least Squares).

- R-squared: Represents the coefficient of determination (R-squared) value.

- Adj. R-squared: This is the adjusted R-squared value, which accounts for the number of predictors in the model and adjusts the R-squared accordingly.

The prediction is same as scikit learn
"""

results.predict(X_sm)

"""<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/754/original/z.png?1705226214' width=800>

We will see more uses of statsmodel library as we continue with today's lecture.

## Assumptions of Linear Regression

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/755/original/z.png?1705226251' width=800>

- We can arrive at concept of Linear regression in two ways.
  - Algebra & Optimization (Geometric) - We covered this
  - Probability & Statistics
- We can prove that Linear regression is a very good model if all the statistical assumptions holds true.

## 1.Assumption of Linearity

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/756/original/z.png?1705226286' width=800>
"""

