# -*- coding: utf-8 -*-
"""SpamDetection-CodeProcessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13yPmhlUOOPcCSgF74605dr1ks6_reBmC
"""

!gdown 1CgBW5H54YfdYtJmYE5GWctaHZSpFt71V

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('spam_ham_dataset.csv')

data[['text','label_num']].head()

import nltk
import string
from nltk.corpus import stopwords
# Download the stopwords if not already downloaded
nltk.download('stopwords')

def text_preprocess(text):
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = [word for word in text.split() if word.lower() not in  stopwords.words('english')]
    return " ".join(text)

text_data = []
for text in data['text'].values:
  clean_text = text_preprocess(text)
  text_data.append(clean_text)

import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer

# Example text data

# Create an instance of TfidfVectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the text data
tfidf_matrix = vectorizer.fit_transform(text_data)

# Print the TF-IDF matrix
print("TF-IDF Matrix:")
print(tfidf_matrix.toarray().shape)

from sklearn.decomposition import PCA

pca = PCA(n_components=15)

# Fit and transform the data
X_pca = pca.fit_transform(tfidf_matrix.toarray())

# Print the transformed data
print("Transformed Data:")
print(X_pca.shape)

temp = {'label_num':data['label_num'].values}

for i in range(X_pca.shape[1]):
  temp[f'Feature{i}'] = X_pca[:,i]

dt = pd.DataFrame(temp)

dt.to_csv('Spam_finalData.csv',index=False)

