# -*- coding: utf-8 -*-
"""7-Regularisation-HyperparameterTuning-KFold.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HyhWxlyKbUhZoMyz6UKe0L7EaaMQliA4

## Content:

- **Regularization**
- **Regularization Code**

- **Hyperparameters**
  - Parameter vs Hyperparameter

  - Steps to choose hyperparameter
  - Plot between lambda($λ$) and adj.R-squared($R^2$)


- **Cross Validation:**
  - Definition and implementation

- **K-fold CV:**
   - Problems with cross-val
   - Definition and implementation

## **Regularization**

#### Which features are useful to have a perfectly fit model?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/112/original/Screenshot_2023-08-16_at_6.54.12_PM.png?1692192581_' width=800></center>

#### How to make $w_1, w_2 \neq 0 $ and $w_3, w_4 = 0$ ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/113/original/Screenshot_2023-08-16_at_6.54.20_PM.png?1692192624' width=800></center>

Here  $d$ is the number of features

<br>

**Note:** This term $\sum_{j=1}^{d} w_j^2$ is called **regularization** and its used:
- So that Gradient Descent works in minimizing values of $w_j $ by making them $≈ 0$

#### Understanding the new Loss function

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/114/original/Screenshot_2023-08-16_at_6.54.27_PM.png?1692192643' width=800></center>

#### How to get that sweet spot between loss function and Regularization ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/115/original/Screenshot_2023-08-16_at_6.54.34_PM.png?1692192678' width=800></center>

#### How does $\lambda$ creates that sweet spot between MSE and Regularization term ?

Ans: With a **right $\lambda$ value** :

1. There is **enough freedom to MSE** so that:
  - The **weights are  optimized** to reach the **lowest possible MSE value**
  - Which **does not lead to overfitting**

2. It also provide **enough freedom to Regularization term** so that:
 - The regularization term can make the weights of the model close to 0
 - Which **does not lead to underfitting**

<br>

**Note:** The term $w_j^2$ is called as L2/Ridge Regularization

## **Points to Remember**

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/117/original/Screenshot_2023-08-16_at_6.54.48_PM.png?1692192728' width=800></center>

## **L-1 Regularization**

#### What do you think, will $\sum_{j=1}^{d} |w_j|$ work ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/120/original/Screenshot_2023-08-16_at_6.55.09_PM.png?1692192872' width=800></center>

<center><img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/123/original/Screenshot_2023-08-16_at_7.33.45_PM.png?1692194777 width=800></center>

## **Interesting property of L1 and L2 Reg**

#### When to use L1, L2 Regularization ?

<center><img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/124/original/Screenshot_2023-08-16_at_7.34.47_PM.png?1692194929 width=800></center>

#### Why does L1 create a sparse W and L2 does not ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/121/original/Screenshot_2023-08-16_at_6.55.16_PM.png?1692192926' width=800></center>

Ans: To figure out why L1 creates a sparse matrix and L2 does not, lets look into weight updation:

- $w_j^{new} =w_j^{old} - \eta \frac{\partial L}{\partial W_j} $

<br>

As **MSE remains same, so the only change** is caused due to **derivative of $|w_j|$ and $w_j^2$**

<br>

#### What do you think, will be the derivative of  $|w_j|$ and $w_j^2$ ?

Ans: for $\frac{d|w_j|}{dw_j} =  [1,0,-1] $ while for $\frac{d|w_j^2|}{dw_j} = 2 \times w_j$

<br>

**observe**
$\frac{d|w_j|}{dw_j}$ is **independent of $w_j$**
- hence quickly reaches 0

<br>

while $\frac{dw_j^2}{dw_j}$ is **dependent on $w_j$**
- hence **when  $w_j$ large**, it **reaches close to 0 very fast**

- But as **$w_j$ approaches zero, the value becomes very small** --> causing **$w_j$ to remain close to 0 only**

#### If you are not sure which regularization to use, is there a way to combine both L1 and L2 ?

<center><img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/122/original/Screenshot_2023-08-16_at_6.59.22_PM.png?1692192957' width=800></center>

## **L1, L2 Regularization Code**

#### Using Sklearn diabetes data - https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset

<img src= https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/110/original/Screenshot_2023-08-16_at_6.03.47_PM.png?1692189250 width=800>
"""

from sklearn import datasets

data = datasets.load_diabetes()

X = data['data']

y = data['target']

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Transform the features into polynomial features
degree = 25
poly = PolynomialFeatures(degree=degree)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Standardize the polynomial features
scaler = StandardScaler()
X_train_poly_scaled = scaler.fit_transform(X_train_poly)
X_test_poly_scaled = scaler.transform(X_test_poly)

"""Using Sklearn's Linear Regression"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train_poly_scaled , y_train)

output = model.predict(X_test_poly_scaled)

"""taking MSE as metric instead of Adj.R-sq"""

from sklearn.metrics import mean_squared_error

print('MSE for test:', mean_squared_error(y_test, output))

output = model.predict(X_train_poly_scaled)
print('MSE for train:', mean_squared_error(y_train, output))

"""**observe**
- Clearly polynomial regression with degree=25 overfits

Lets see how L1 and L2 regularisation work
"""

from sklearn.linear_model import Lasso, Ridge

lasso_model = Lasso(alpha=0.01)  # Alpha is the regularization strength
ridge_model = Ridge(alpha=1.0)    # Alpha is the regularization strength

# Fit the models to the training data
lasso_model.fit(X_train_poly_scaled, y_train)
ridge_model.fit(X_train_poly_scaled, y_train)

lasso_predictions = lasso_model.predict(X_test_poly_scaled)
ridge_predictions = ridge_model.predict(X_test_poly_scaled)

print('test MSE for L1:', mean_squared_error(y_test, lasso_predictions))
print('test MSE for L2:', mean_squared_error(y_test, ridge_predictions))

"""**observe**

Using Regularisation the test MSE reduces for our Polynomial regression model with degree=25

This shows how regularisation helps the model

## **Points to Remember**

<center><img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/125/original/Screenshot_2023-08-16_at_7.35.10_PM.png?1692194983 width=800> </center>

<center><img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/043/126/original/Screenshot_2023-08-16_at_7.35.19_PM.png?1692195015 width=800> </center>

## Hyperparameters

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/826/original/z.png?1705229761' width=800>

#### What do you mean by parameters and hyperparameters then?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/827/original/z.png?1705229790' width=800>

Any kind of value which the data scientist sets from their side.

E.g.:
  - Degree of the model
  - Regularization Rate, lamdba, $λ$

and so on.

#### How do we choose the hyperparameter values?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/828/original/z.png?1705229816' width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/829/original/z.png?1705229845' width=800>

<!-- In some cases, we also use performance metric instead of error to find the optimal value (as we did earlier) -->

#### What would the plot between $λ$ and $adj. R^2$ score look like?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/830/original/z.png?1705229875' width=800>

Let's use the code to create X and Y as we did in last lecture
"""

import numpy as np
import matplotlib.pyplot as plt

# lets generate a dataset of 100 points
np.random.seed(2)
X = np.random.rand(1000,1)
y = 0.7*(X**5) - \
    2.1*(X**4) + \
    2.3*(X**3) + \
    0.2*(X**2) + \
    0.3* X + \
    0.4*np.random.rand(1000,1)

"""Now we divide our data into train and test"""

#0.8, 0.2 split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

X_train.shape, X_test.shape

"""If you remember, we had already seen how to find the optimal value of degree for polynomial regression in the last lecture

Let's use L2/Ridge regression model to tune our hyperparameters-degree and regularization rate
"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline

# Defining our performance metric
def adj_r2(X, y, r2_score):
  return 1 - ((1-r2_score)*(len(y)-1))/(len(y)-X.shape[1]-1)

# Same as last lecture
max_degree = 25 # max polynomial degree
train_scores = []
test_scores = []
scaler = StandardScaler()
for degree in range(1, max_degree):
  polyreg_scaled = make_pipeline(PolynomialFeatures(degree), scaler, Ridge())
  polyreg_scaled.fit(X_train, y_train)
  train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
  test_score= adj_r2(X_test, y_test, polyreg_scaled.score(X_test, y_test))
  train_scores.append(train_score)
  test_scores.append(test_score)

plt.figure()
plt.plot(list(range(1, 25)), train_scores, label="train")
plt.plot(list(range(1, 25)), test_scores, label="test")
plt.legend(loc='lower right')
plt.xlabel("degree")
plt.ylabel("adj. R-score")
plt.grid()
plt.show()

"""
Based on this, the optimal degree would be somewhere around 3.

Now let's see how to optimize our regularization rate."""

train_scores = []
test_scores = []
rate_list = [0.01, 0.1, 1,5, 10]
scaler = StandardScaler()
for rate in rate_list:
  polyreg_scaled = make_pipeline(PolynomialFeatures(3), scaler, Ridge(alpha=rate))
  polyreg_scaled.fit(X_train, y_train)
  train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
  test_score= adj_r2(X_test, y_test, polyreg_scaled.score(X_test, y_test))
  train_scores.append(train_score)
  test_scores.append(test_score)

plt.figure()
plt.plot(rate_list, train_scores, label="train")
plt.plot(rate_list, test_scores, label="test")
plt.legend(loc='lower right')
plt.xlabel("lambda")
plt.ylabel("adj. R-score")
plt.grid()
plt.show()

test_scores

"""Our optimal lambda value comes out to be around 0.01 based on the test

## Cross-Validation

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/832/original/z.png?1705229945' width=800>

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/833/original/z.png?1705229973' width=800>

#### So how do we perform cross validation?
"""

# lets generate a dataset of 100 points
np.random.seed(2)
X = np.random.rand(1000,1)
y = 0.7*(X**5) - \
    2.1*(X**4) + \
    2.3*(X**3) + \
    0.2*(X**2) + \
    0.3* X + \
    0.4*np.random.rand(1000,1)

"""Now we divide our data into train, test and validation"""

#0.6, 0.2, 0.2 split
from sklearn.model_selection import train_test_split
X_tr_cv, X_test, y_tr_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
X_train, X_val, y_train, y_val = train_test_split(X_tr_cv, y_tr_cv, test_size=0.25,random_state=1)

X_train.shape, X_val.shape, X_test.shape

"""Let's visualize our data"""

plt.figure(figsize=(18,5))
data_labels = ["Training Data", "Validation Data", "Test Data" ]
x_labels = [X_train, X_val, X_test]
y_labels = [y_train, y_val, y_test]
for i in range(3):
  plt.subplot(1, 3, i+1)
  plt.scatter(x_labels[i], y_labels[i])
  plt.xlabel("x")
  plt.ylabel("y")
  plt.title(data_labels[i])

"""The statistics of our type of data is similar, so we are good to go.

#### Steps to do cross-validation on our data

Now if you remember, in the last lecture we saw how the performance was increasing with increase in degree of the polynomial model

But how do we find the optimal degree in this case?

Let's

Let's try to find the optimal value of `degree` for our polynomial regression model

1. First we take degrees from 1 to 25, and train the model on data for each of these degrees to find the best degree
"""

# Same as we did earlier and in the last lecture
max_degree = 25 # max polynomial degree
train_scores = []
val_scores = []
scaler = StandardScaler()
for degree in range(1, max_degree):
  polyreg_scaled = make_pipeline(PolynomialFeatures(degree), scaler, Ridge())
  polyreg_scaled.fit(X_train, y_train)
  train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
  val_score= adj_r2(X_val, y_val, polyreg_scaled.score(X_val, y_val))
  train_scores.append(train_score)
  val_scores.append(val_score)
plt.figure()
plt.plot(list(range(1, 25)), train_scores, label="train")
plt.plot(list(range(1, 25)), val_scores, label="val")
plt.legend(loc='lower right')
plt.xlabel("degree")
plt.ylabel("adj. R-score")
plt.grid()
plt.show()

"""Taking degree=3, we now find the best regularization rate by the same process"""

train_scores = []
val_scores = []
rate_list = [0.01, 0.1, 1,5, 10]
for rate in rate_list:
  polyreg_scaled = make_pipeline(PolynomialFeatures(3), scaler, Ridge(alpha=rate))
  polyreg_scaled.fit(X_train, y_train)
  train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
  val_score= adj_r2(X_val, y_val, polyreg_scaled.score(X_val, y_val))
  train_scores.append(train_score)
  val_scores.append(val_score)

plt.figure()
plt.plot(rate_list, train_scores, label="train")
plt.plot(rate_list, val_scores, label="val")
plt.legend(loc='lower right')
plt.xlabel("lambda")
plt.ylabel("adj. R-score")
plt.grid()
plt.show()

"""We take the optimal value of lambda as 0.01

2. Now finally, we measure our model's performance on test data, which our model hasn't seen till now
"""

polyreg_scaled = make_pipeline(PolynomialFeatures(3), scaler, Ridge(alpha=0.01))
polyreg_scaled.fit(X_train, y_train)
train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
print(f'Training Score = {train_score}')
val_score = adj_r2(X_val, y_val, polyreg_scaled.score(X_val, y_val))
print(f'Validation Score = {val_score}')

# Reporting this as the final score
test_score = adj_r2(X_test, y_test, polyreg_scaled.score(X_test, y_test))
print(f'Testing Score = {test_score}')

"""Observe, the test results are lower than training and validation.

This is because, our model hasn't seen the test data at all, and this can be said as the true result of our model.

#### Try for yourself

- Try to use Linear Regression, Lasso and ElasticNet and see how do the results vary?

But there is one issue with cross validation when there are less number of data points

## K-Fold Cross Validation

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/837/original/z.png?1705230186' width=800>

#### How do we validate our data in case of lesser number of data points?

We use **K-Fold Cross Validation**

This is useful only for small datasets

#### What is k-fold cross validation?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/838/original/z.png?1705230217' width=800>

#### How to implement K-Fold Cross validation?

<img src='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/061/839/original/z.png?1705230256' width=800>

Let's look at the implementation.
"""

# Creating a small dataset of 100 data points
np.random.seed(2)
X = np.random.rand(100,1)
y = 0.7*(X**5) - \
    2.1*(X**4) + \
    2.3*(X**3) + \
    0.2*(X**2) + \
    0.3* X + \
    0.4*np.random.rand(100,1)

from sklearn.model_selection import KFold
kf = KFold(n_splits=10)

# Performing k-fold cross validation
degrees = 15 # number of degrees
train_scores = []
val_scores = []

for degree in range(1, degrees):
    fold_train_scores = []
    fold_val_scores = []

    for train_index, val_index in kf.split(X): #iterating through the K-folds

        X_train, X_val = X[train_index], X[val_index]
        y_train, y_val = y[train_index], y[val_index]

        polyreg_scaled = make_pipeline(PolynomialFeatures(degree), scaler, LinearRegression())
        polyreg_scaled.fit(X_train, y_train) #training model

        train_score = adj_r2(X_train, y_train, polyreg_scaled.score(X_train, y_train))
        val_score= adj_r2(X_val, y_val, polyreg_scaled.score(X_val, y_val))

        fold_train_scores.append(train_score)
        fold_val_scores.append(val_score)

    train_score = np.mean(fold_train_scores)
    val_score = np.mean(fold_val_scores)

    train_scores.append(train_score)
    val_scores.append(val_score)

plt.figure()
plt.plot(list(range(1, 15)), train_scores, label="train")
plt.plot(list(range(1, 15)), val_scores, label="val")
plt.legend(loc='lower right')
plt.xlabel("degree")
plt.ylabel("Average R2 score")
plt.show()

"""Note:

- K-Fold Cross Validation can be computationally expensive
- Hence it's only used for Small datasets
- For large datasets, we have enough datapoints to train the model, hence only cross validation is sufficient
"""